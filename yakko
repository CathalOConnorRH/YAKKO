#!/bin/bash
#set -x

###########################################################################
# YAKKO - Yet another KVM Konfigurator for OpenShift
# AUTHOR: Daniel Cifuentes
# 
# A COVID Pandemic Confinement project - Circa 09/2020 
# First version was tried on 4.5 
# Reverted to OCP 4.3 try single node, which is not supported in 4.4+
###########################################################################

# Inspirational documentation for this:
# https://github.com/eitchugo/openshift-libvirt/blob/master/OpenShift_4_libvirt_install_1_master.md

##########################################################################
# BACKLOG:
# - use chrony
# - add timer in case addnode fails
# 
# COMPLEX:
# - Work on non-virtual network. That may be a project for the next pandemic
##########################################################################

######## THESE CAN BE USER CONFIGURABLE FOR FURTHER TESTING.
######## FEEL FREE TO ADJUST AND TRY YOUR LUCK
MASTERVCPUS=4 # Recommended 4
WORKERVCPUS=2 # Recommended 2
MASTERDISKSIZE=20
WORKERDISKSIZE=20
MAXNODEVCPUS=4
MAXWORKERNODES=5 # 5 worker nodes sounds like a reasonable number?

# THESE CAN BE CHANGED INTERACTIVELY #####################################
MASTERRAMSIZE=10000 # Recommended 8192. 6000 not enough
WORKERRAMSIZE=4000 # Recommended ... 2048!? Worked well with 5Gi. Setting up as 8 to do some real work
# DEPRECATED ... CLUSTERNODECONFIG=1 # There are 3 config scenarios, 3+0, 3+1, 3+2 for now
##########################################################################

# This is in prep for building single node clusters, do not reverse!
MASTERNODECOUNT=3  

#These two will go hand in hand but we'll keep them separate should one ever attempt a non-virtual network 
BASENETWORK="192.168.140"
BASEMACADDRESS="52:54:00:4a:66"
PROXYADDRESS=1  # So that the overall "proxy" to the cluster is BASENETWORK.PROXY e.g. 192.168.140.1

# A few final parameters
YAKKONAME=yakko   # In case we want to change the name of the script
YAKKOSETUPDIR=/YAKKO
AUTOSETUP=0 # 1 is Auto, 0 is manual
OCPSSHKEY=~/.ssh/id_rsa_ocp
IMAGEREPO=${YAKKOSETUPDIR}/images # The webserver will serve from here. oc and openshift-install are here already
CLUSTERCONFIGFILE=.clusterconfig # Filename where all defaults for the cluster you are building are kept
PULLSECRETFILE=.pullsecret
YAKKODEFAULTS=.yakkodefaults # Filename where all defaults for YAKKO are kept
YAKKOSTAGE=0
STAGEPROGRESS=0
BACKUPDEVICES="/mnt/NFS/YAKKO-BACKUPS /mnt/YAKKO-USB"
OCPWGETTMP=/tmp/ocpsetupwget.tmp
OCPVMDISKDIR=/var/lib/libvirt/images
CLUSTERDOMAIN=localdomain  
DNSMASQCONFIGFILE=/etc/NetworkManager/dnsmasq.d/dnsmasq-${YAKKONAME}.conf

# Some parameter options
YAKKOINFRAOPTIONS=" startcluster / stopcluster / addnode / deletenode / nodelogs / sshtonode / openaccess / deletecluster "
YAKKOCLUSTEROPTIONS=" htpasswd / useradd / userdelete / mastersched / nodelabel / localregistry / yakkotest "

# Decorations
SEPARATIONLINE="__________________________________________________________________________"


################ A FEW INITIALISATION FUNCTIONS ################################################

populate-clusterconfigfile() {
	# CLUSTERCONFIGFILE CREATION
	# Populate the config file with some references for future calls
	{
		echo "CLUSTERNAME=${CLUSTERNAME}" 
		echo "CLUSTERFQDN=${CLUSTERFQDN}"
		echo "CLUSTERWEBURL=${CLUSTERWEBURL}"
		echo "CLUSTERAPIURL=${CLUSTERAPIURL}"
		echo "YAKKOSTAGE=0"
		echo "CLUSTERSETUPDIR=${CLUSTERSETUPDIR}" 
		echo "NETWORKNAME=${NETWORKNAME}" 
		echo "OCPGETCLIENTVERSION=${OCPGETCLIENTVERSION}"
		echo "NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml"
		echo "NETWORKADDRESSSLOT=20"
		echo "NODECOUNT=0"

	} > ${CLUSTERCONFIGFILE}

	source ${CLUSTERCONFIGFILE}
}

populate-yakkodefaults() {

	{
		echo "CLUSTERNAME=${CLUSTERNAME}"
		echo "CLUSTERDOMAIN=${CLUSTERDOMAIN}"
		echo "OCPVMDISKDIR=${OCPVMDISKDIR}"
		echo "MASTERNODECOUNT=${MASTERNODECOUNT}"
		echo "WORKERNODECOUNT=${WORKERNODECOUNT}"
		echo "CLUSTERPROXY=${CLUSTERPROXY}"
		echo "WEBSERVERIP=${WEBSERVERIP}"
		echo "WEBSERVERPORT=${WEBSERVERPORT}"
		echo "WEBSERVERURL=http://${WEBSERVERIP}:${WEBSERVERPORT}"
		# DEPRECATED ... echo "CLUSTERNODECONFIG=${CLUSTERNODECONFIG}"
	
		# NETWORK CONFIGURATION
		echo "BASEMACADDRESS=${BASEMACADDRESS}"
		echo "BASENETWORK=${BASENETWORK}"

		# This will be used for creating nodes later on so that any new nodes start at $NETWORKADDRESSSLOT
		# Note that bootstrap and masters have fixed numbers for IP and MAC
		# 52:54:00 is KVM/QEMU default    4A:66:00 is a tranliteration of YAKKO ;)
		# All worker nodes will begin with MAC and IP $NETWORKADDRESSSLOT
		echo "NETWORKADDRESSSLOT=20"
		echo "BOOTSTRAPMAC=${BASEMACADDRESS}:09"
		echo "MASTER0MAC=${BASEMACADDRESS}:10"
		echo "MASTER1MAC=${BASEMACADDRESS}:11"
		echo "MASTER2MAC=${BASEMACADDRESS}:12"
		echo "BOOTSTRAPIP=${BASENETWORK}.9"
		echo "MASTER0IP=${BASENETWORK}.10"
		echo "MASTER1IP=${BASENETWORK}.11"
		echo "MASTER2IP=${BASENETWORK}.12"

	} > ${YAKKODEFAULTS}

	source ${YAKKODEFAULTS}
}

################ A FEW REUSABLE FUNCTIONS ################################################


print-in-green() {
        tput setaf 2;tput bold
	echo "$*"
        tput sgr0
}


print-time-elapsed() {

	TIMEELAPSEDSECS=$(( $SECONDS - $TIMESTART))
	TIMEELAPSEDMINS=$(( $TIMEELAPSEDSECS / 60 ))

	print-in-green "Time elapsed: " ${TIMEELAPSEDMINS} mins $(( ${TIMEELAPSEDSECS} - (${TIMEELAPSEDMINS} * 60 ) )) secs

}


query-user() {

        # $1 is the string to display
	# $2 is the default if user presses <ENTER>
        # $3 as "noauto" ignores the AUTOSETUP flag
        DIALOGUETEXT=$1
	DEFAULTRESPONSE=$2
        NOAUTO=$3

	# We are within a stage, so we need to setup a trap to rollback
	[ ! -z "${CURRENTSTAGE}" ] && trap "echo; echo 'Input interrupted. Aborting.'; ${CURRENTSTAGE} rollback; echo; exit" SIGINT

	if [ $AUTOSETUP -eq 1 -a "$NOAUTO" == ""  ]
	then 
		# if in AUTO mode return DEFAULTRESPONSE
                if [ "$DEFAULTRESPONSE" == "y" -o "$DEFAULTRESPONSE" == "Y" ]
                then
                        return 0
                elif [ "$DEFAULTRESPONSE" == "n" -o "$DEFAULTRESPONSE" == "N" ]
                then
                        return 1 # 1 = false!
		fi
	fi

 	while [ 1 ]
        do
                echo -n "$DIALOGUETEXT - proceed [y/n]? "
                read RESPONSE

		[ -z "${RESPONSE}" ] && RESPONSE=${DEFAULTRESPONSE} 

                if [ "$RESPONSE" == "y" -o "$RESPONSE" == "Y" ]
                then
                        return 0
                elif [ "$RESPONSE" == "n" -o "$RESPONSE" == "N" ]
                then
                        return 1 # 1 = false!
                else
                        echo "Invalid reponse [$RESPONSE]."
                fi
        done
}


check-for-error-and-exit() {
	# Something bad got caught somewhere - write this out and abort
	# $1 is the error code passed (0 is good)
	# $2 is a string to report

	# There is no error found
	[ "$1" -eq 0 ] && return

	# Else... Doom!
	echo
	echo "ERROR: $2. Exiting."
	echo

	if [ ! -z "${CURRENTSTAGE}" ]
	then
		#We are within a stage so we rollback
		query-user "Rollback steps of this stage (y) or leave for debugging (n)?" "Y" noauto
		[ $? -eq 0 ] && ${CURRENTSTAGE} rollback 
	fi
	echo
	exit
}


install-package-if-missing() {
	
	# $1 is the package to check for
	PACKAGE=$1

	dnf list installed | grep $PACKAGE > /dev/null 2>&1
	[ $? -ne 0 ] && {
		echo Installing package [$PACKAGE]
		dnf -y install $PACKAGE
		check-for-error-and-exit $? "Failed to install package [$PACKAGE]"
	}
}

delete-kvm-machine()
{
	NODETODELETE=$1

	# This is a safety measure...

	echo ${NODETODELETE} | grep -E '^node|^master|^bootstrap' > /dev/null 2>&1
	if [ $? -eq 0 ]
	then
		echo ${NODETODELETE} | grep ${CLUSTERFQDN} > /dev/null 2>&1
		[ $? -ne 0 ] && NODETODELETE=${NODETODELETE}.${CLUSTERFQDN}
		virsh destroy ${NODETODELETE}
		virsh undefine --domain ${NODETODELETE} --remove-all-storage
	else
		echo "ERROR: Tried to delete non-OCP/YAKKO KVM machine: [$${NODETODELETE}]"
		exit
	fi
	
}


advance-stage-progression() {

	# We skip all stages until we get to the one we were in...
	((++STAGEPROGRESS))

	#We'll get a timestamp of the first stage for a final run report
	[ -z "${TIMESTART}" ] && TIMESTART=$SECONDS

	if [ ${STAGEPROGRESS} -lt ${YAKKOSTAGE} ]
	then
		return 0
	else
		echo
		print-in-green ${SEPARATIONLINE}
		echo
		print-in-green "STAGE ${STAGEPROGRESS}: $1 (Time start: $(date +%H:%M%p))"
		echo
	
		# We write the stage we are at so that we can return if desired
		sed -i "/YAKKOSTAGE.*/c\YAKKOSTAGE=${STAGEPROGRESS}" ${CLUSTERCONFIGFILE} 2>/dev/null

		# Since this stage will progress, we capture CTRL-C to rollback 
		# we set it to 0 so that the running advance-stage can call itself back
		trap 'echo; ${FUNCNAME[0]} rollback; echo; exit' SIGINT

		# And we set the CURRENTSTAGE in case we have to rollback from a deeper function, to ease lookup
		# This works because advance-stage-progression CAN ONLY be called within a stage, and at the begining!
		CURRENTSTAGE=${FUNCNAME[1]}

		return 1
	fi
}


rollback-stage-progression() {
	echo
	echo ROLLBACK STAGE: $*
}


get-node-list() {

	# call: get-node-list <all|active> [print]

	if [ $1 == "all" ]
	then
		NODELIST=" $(virsh list --all --name | grep -e "master-" -e "node-" -e "bootstrap") "
	fi

	if [ $1 == "active" ]
	then
		NODELIST=" $(virsh list --name | grep -e "master-" -e "node-" -e "bootstrap") "
	fi

	if [ "$2" == "print" ]
	then
		#we also print the list in columns
		for NODE in ${NODELIST}
		do
			echo ${NODE}
		done
	fi
}

pick-a-node() {

	# Call: pick-a-node <string-to-display-for-chooser-query>
	while [ 1 ]
	do
		echo "Available nodes for this action are:"
		get-node-list active print
		echo
		echo -n "$1: "
		read NODENAME
		[ $? -eq 0 ] && break
	done
}
	

print-cluster-administrator() {
	if [ ! -z "${YAKKOADMIN}" ]
	then
		echo "Administrator: ${YAKKOADMIN}  (Password not available for display)"
	else
		echo "Administrator: kubeadmin"
		echo "Password:      $(cat ${CLUSTERSETUPDIR}/auth/kubeadmin-password)"
	fi
}


check-cluster-state() {
	# Call: check-cluster-state <0|1> ["api"]
	# if $1 ==  0 don't print state
	# if $1 ==  1 print state AND EXIT
	# if $2 == power just check for the power status of the cluster
	# if $2 is the string "api" then we don't bail if the API server is up as some calls 
	# are looking for this to function, for example if I need a worker node for some
	# operators to come up.
	# Valid calls are:
	# check-cluster-state 1
	# check-cluster-state 0
	# check-cluster-state 0 api

	# Return values are
	# 0 -> All good
	# 1 -> API not good
	# 2 -> Web Console not good
	# 3 -> API and Web Console not good
	# 4 -> Cluster is shutdown!

	PRINTSTATE=$1
	SPECIALQUERY=$2

	# This is only executed at the end of the process or on subsequent calls

	source ${CLUSTERCONFIGFILE}

	MASTERUPCOUNT=$(virsh list --all | grep "master-" | grep "running" | wc -l)

	if [ "${SPECIALQUERY}" == "power"  ]
	then
		if [ ${MASTERUPCOUNT} -eq 0 ]
		then
			return 4 # Special case - the cluster is SHUTDOWN!
		else
			return 0 # The cluster is powered up
		fi
	fi

	# Are we logged into OpenShift first?
	#oc whoami > /dev/null 2>&1
	#[ $? -eq 1 ] && {
	#	echo
	#
	#		echo "You are not authorised in the OpenShift server. Are you logged in?"
	#		echo "(try  oc login -u <administrator>)"
	#		echo
	#		print-cluster-administrator
	#		echo
	#		exit
	#	}

	# If the web console is available, offer info for it regardless of the output above
	RESULTCONSOLE=1
	wget -O $OCPWGETTMP ${CLUSTERWEBURL} --no-check-certificate > /dev/null 2>&1
	RESULTCONSOLE=$?

	RESULTSERVER=1
	wget -O $OCPWGETTMP ${CLUSTERAPIURL} > /dev/null 2>&1
	RESULTSERVER=$?
	[ $RESULTSERVER -eq 5 ] && RESULTSERVER=0 # SSL errors doesn't mean it's not up

	[ $RESULTCONSOLE -eq 0 -a $RESULTSERVER -eq 0 ] && OCPACCESSSTATUS=0 # All good
	[ $RESULTCONSOLE -eq 0 -a $RESULTSERVER -ne 0 ] && OCPACCESSSTATUS=1 # API not good
	[ $RESULTCONSOLE -ne 0 -a $RESULTSERVER -eq 0 ] && OCPACCESSSTATUS=2 # Web Console not good
	[ $RESULTCONSOLE -ne 0 -a $RESULTSERVER -ne 0 ] && OCPACCESSSTATUS=3 # API and Web Console not good
		
	if [ ${PRINTSTATE} -ne 0 ] 
	then 
		# we are asked to print state
		echo "CLUSTER: ${CLUSTERFQDN}  "   
		echo

		if [ $OCPACCESSSTATUS -eq 3 ]
		then 
			if [ ${MASTERUPCOUNT} -eq 0 ]
			then
				echo "All nodes of the cluster are currently powered off."
			else
				echo "ERROR: The cluster does not appear to be accessible or there is no console active yet."
				echo
				echo "You can check the status of the masters by issuing, for example: "
				echo "ssh -i $OCPSSHKEY core@master-0.${CLUSTERFQDN}  journalctl -b -f -u crio.service"
				echo
				echo "or simply: $0 sshtonode master-0"
			fi	
			echo
		else
			TOTALMASTERS=$(virsh list | grep "master-" | wc -l)
			TOTALNODES=$(virsh list | grep "node-" | wc -l)
			TOTALOPERATORS=$(oc get co | grep -v AVAILABLE | wc -l)
			ACTIVEOPERATORS=$(oc get co | grep -v AVAILABLE | awk '{print $3}' | grep True | wc -l)

			echo "Active Masters:   ${TOTALMASTERS}"
			echo "Active Nodes:     ${TOTALNODES} (workers/infra)"

			echo "Active Operators: ${ACTIVEOPERATORS}/${TOTALOPERATORS}"

			echo
			echo "             state      "
			if [ $OCPACCESSSTATUS -eq 0 ] 
			then
				#echo "The console and API server appear to be operational:"
				echo "Web Console: [ ✔ ]  ${CLUSTERWEBURL}"
                                echo "API Server:  [ ✔ ]  ${CLUSTERAPIURL}"
			elif [ $OCPACCESSSTATUS -eq 1 ]
			then
				#echo "The console appears to be operational, the API server does not:"
				echo "Web Console: [ ✔ ]  ${CLUSTERWEBURL}"
                                echo "API Server:  [ ✘ ]" 
			elif [ $OCPACCESSSTATUS -eq 2 ]
			then
				#echo "The API server appears to be operational, the console does not:"
				echo "Web Console: [ ✘ ]"
                                echo "API Server:  [ ✔ ]  ${CLUSTERAPIURL}"
			fi
			echo
			#echo "Web console:   $(${OCPINSTALLSOURCE}/oc whoami --show-console)"
			#echo "API server:    $(${OCPINSTALLSOURCE}/oc whoami --show-server)"
			#echo
			print-cluster-administrator
			echo
			echo "- To use OpenShift's 'oc' command run: \"source ocp-setup-env\" in this shell."
			echo "- To make infrastructure changes use:  \"${YAKKONAME} infra <options>\"  "
			echo "- To make operational changes use:     \"${YAKKONAME} ops <options>\" "
			echo
		fi

		# AND WE EXIT after printing STATUS of the cluster
		exit
	else
		# We are not being asked to pring anything
		# We manipulate the return value if we are just being asked about the API server
		if [ ${SPECIALQUERY} == "api" -a ${OCPACCESSSTATUS} == 2 ]
		then
			OCPACCESSSTATUS=0
		fi
	fi

	echo

	return ${OCPACCESSSTATUS}
}


build-ocp-node() {

	trap 'echo; ${FUNCNAME[1]} rollback; exit' SIGINT

	#master example is  build-ocp-node master-X 52:00:84:12:34:56 $MASTERVCPUS $MASTERRAMSIZE $MASTERDISKSIZE master.ign

	NODEHOSTNAME=$1 

	# Check if httpd is up - I've hit this before
	systemctl is-active httpd > /dev/null 2>&1
	[ $? -ne 0 ] && {
		systemctl restart httpd
		check-for-error-and-exit $? "Provisioning HTTPD server seems to be inactive - cannot continue building node"
	}

	if [ "$2" == "auto" ]
	then
		# If $1 is not 'auto' it's because the MAC has been passed - for MASTER nodes only
		# If not, we're creating a new WORKER node, this calls for an auto mac and ip address
		NODEMACADDRESS=${BASEMACADDRESS}:${NETWORKADDRESSSLOT}

		# Update the networking tables for KVM
		# This function adds a dhcp entry in the virtual network table by inserting 
		# it in the DHCP scope XML definition and then restarting the network!
 		# <host mac='${NODEMAC}' name='nodename.${CLUSTERFQDN}' ip='${NODEIP}'/>"

		HOSTDHCPENTRY="<host mac=\"${NODEMACADDRESS}\" name=\"${NODEHOSTNAME}.${CLUSTERFQDN}\" ip=\"${BASENETWORK}.${NETWORKADDRESSSLOT}\"/>"
		sed -i "/<\/dhcp>/i\			${HOSTDHCPENTRY}" ${NETWORKXML}

		# Restart the network
		echo "Restarting virtual network"
		virsh net-update ${NETWORKNAME} add-last ip-dhcp-host "${HOSTDHCPENTRY}" --live --config 
                check-for-error-and-exit $? "Could not restart the virtual network"

		# Update the HAproxy and restart it
		echo "Updating and restarting HAproxy"
		sed -i "/addingressrouternode80/a\    server ${NODEHOSTNAME} ${BASENETWORK}.${NETWORKADDRESSSLOT}:80 check inter 1s" /etc/haproxy/haproxy.cfg
		sed -i "/addingressrouternode443/a\    server ${NODEHOSTNAME} ${BASENETWORK}.${NETWORKADDRESSSLOT}:443 check inter 1s" /etc/haproxy/haproxy.cfg
                systemctl restart haproxy
                check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."

		# Update the last mac address used in the CLUSTERCONFIGFILE 
		((NETWORKADDRESSSLOT++))
		sed -i "/NETWORKADDRESSSLOT=/c\NETWORKADDRESSSLOT=${NETWORKADDRESSSLOT}" ${CLUSTERCONFIGFILE}
	else
		NODEMACADDRESS=$2
	fi

	NODEVCPUS=$3
	NODERAMSIZE=$4
	NODEDISKSIZE=$5
	IGNITIONFILE=$6

	echo "Building OCP node: ${NODEHOSTNAME} (MAC Addr: ${NODEMACADDRESS})"

	if [ $(echo ${OCPINSTALLVERSION} | cut -c3 ) -gt 5 ]  # We are on OCP 4.6 or higher
	then
		virt-install \
			--memory ${NODERAMSIZE} \
			--vcpus ${NODEVCPUS} \
			--cpu host \
			--disk path=${OCPVMDISKDIR}/${NODEHOSTNAME}.${CLUSTERFQDN}.qcow2,size=${NODEDISKSIZE},bus=virtio,format=qcow2 \
			--install kernel=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-kernel-x86_64,initrd=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-initramfs.x86_64.img,kernel_args_overwrite=yes,kernel_args="coreos.inst=yes coreos.inst.install_dev=vda coreos.live.rootfs_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-live-rootfs.x86_64.img coreos.inst.image_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-metal.x86_64.raw.gz coreos.inst.ignition_url=${WEBSERVERURL}/${IGNITIONFILE} coreos.inst.insecure ip=dhcp rd.neednet=1" \
			--os-type=linux \
			--os-variant=rhel8-unknown \
			--graphics vnc \
			--network network=${NETWORKNAME},mac=${NODEMACADDRESS}  \
			--noautoconsole --wait -1 \
			--name ${NODEHOSTNAME}.${CLUSTERFQDN}
		BUILDOCPNODERESULT=$?
	else
      		virt-install \
	                --memory ${NODERAMSIZE} \
	       	         --vcpus ${NODEVCPUS} \
       		         --cpu host \
       		         --disk path=${OCPVMDISKDIR}/${NODEHOSTNAME}.${CLUSTERFQDN}.qcow2,size=${NODEDISKSIZE},bus=virtio,format=qcow2 \
       		         --install kernel=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-installer-kernel-x86_64,initrd=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-installer-initramfs.x86_64.img,kernel_args_overwrite=yes,kernel_args="coreos.inst=yes coreos.inst.install_dev=vda coreos.inst.image_url=${WEBSERVERURL}/${OCPINSTALLVERSION}/rhcos-metal.x86_64.raw.gz coreos.inst.ignition_url=${WEBSERVERURL}/${IGNITIONFILE} ip=dhcp rd.neednet=1" \
       		         --os-type=linux \
       		         --os-variant=rhel8-unknown \
       		         --graphics vnc \
       		         --network network=${NETWORKNAME},mac=${NODEMACADDRESS}  \
       		         --noautoconsole --wait -1 \
       		         --name ${NODEHOSTNAME}.${CLUSTERFQDN}
		BUILDOCPNODERESULT=$?
	fi

	# We clear any old entries in known hosts so that user sees no nasty security business
	sed -i "/${NODEHOSTNAME}.${CLUSTERFQDN}/d" /root/.ssh/known_hosts > /dev/null 2>&1

	return $BUILDOCPNODERESULT
}


approve-csrs-normal() {

	CSRAPPROVALPID=0

	if [ $CSRAPPROVALPID -eq 0 ]
	then
		# running oc here is a little tickier as this gets forked off, so we test for it before
		[ -x ${OCPINSTALLSOURCE}/oc ] 
		check-for-error-and-exit $? "Cannot process CSRs as this stage cannot execute command ${OCPINSTALLSOURCE}/oc"

		# This runs in the backgound approving certificates as they come...
		{
			trap "echo; echo 'CSR Approvals (oc get csr) stopped...'; exit" SIGQUIT

			while [ 1 ] 
			do
				${OCPINSTALLSOURCE}/oc get csr 2>/dev/null | grep Pending | awk '{ print $1 }' | xargs ${OCPINSTALLSOURCE}/oc adm certificate approve > /dev/null 2>&1
				#check-for-error-and-exit $? "Could not retrieve CSRs"
				sleep 10
			done
		} &
		CSRAPPROVALPID=$!
	fi
		
	trap 'kill -s SIGQUIT $CSRAPPROVALPID ; sleep 2; echo; echo "Shutting down CSR approvers, please wait..."; sleep 20; exit' SIGINT
}


yakko-backup() {

	# A small developer backdoor...
	# Too lazy to push to git all the time
	# $2 creates a message that accompanies the backup... Like commit -m ;)

	BACKUPFILE=${YAKKONAME}.$(date +%Y%m%d.%H%M)
	BACKUPMSG="$*"

	for YBD in ${BACKUPDEVICES}
	do
		if [ ! -d "$YBD" ]
		then
			cp $0 /${BACKUPFILE}
			echo
			echo "ERROR: [$YBD] cannot be written to for backup."
			echo "NOTE: A backup has been made in the root directory (/)"
			break
		fi
			
		cp $0 $YBD/${BACKUPFILE}
		rm $YBD/${YAKKONAME}
		cp $0 $YBD/${YAKKONAME} # This will always be the latest. ln does not work on VFAT ;)
		if [ ! -z "$BACKUPMSG" ]
		then
			echo $BACKUPMSG > $YBD/${BACKUPFILE}.txt
		fi
	done

	echo "Backed up current ${YAKKONAME} as ${BACKUPFILE}"
	echo
	exit
}


yakko-infra-operations() {

	# We're here bacause 'yakko infra' was invoked

	# $1 is an op listed in $YAKKOINFRAOPTIONS
	# YAKKOINFRAOPTIONS is defined at the top with the list of valid ops on an existing cluster	

	OPTION=$1
	echo "${YAKKOINFRAOPTIONS}" | grep " ${OPTION} " > /dev/null

	if [ $? -ne 0 -o -z "${OPTION}" ]
	then
		# Catchall for any other passed parameted at this point
		echo "USAGE: ${YAKKONAME} infra <OPTION> [parameters]" 
		echo
		echo "OPTION is one of:"
		echo "    - startcluster  -> start up an existing cluster"
		echo "    - stopcluster   -> shutdown an existing cluster"
		echo "    - addnode       -> grow the cluster compute capacity by adding a new compute/infra node"
		echo "    - deletenode    -> remove a running node from the cluster"
		echo "    - nodelogs      -> display the logs of a particular node"
		echo "    - sshtonode     -> provide terminal access to an individual cluster node"
		echo "    - openaccess    -> enable OpenShift access by other clients in your network"
		echo "    - deletecluster -> delete entire cluster and all infrastructure"
		echo
		exit
	fi

	if [ ${OPTION} == "startcluster" ]
	then
		#infrastartcluster

		# Sometimes, HA Proxy may not be running...
		echo "(Re)starting HA Proxy..."
		echo
		systemctl restart haproxy
		check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."
		
		if [ ! -z "$2" ]
		then
			# Surely the user knows what he's doing...
			NODENAME=$2
       	 		echo "Starting up: ${NODENAME}"
       	 		virsh start ${NODENAME}.${CLUSTERFQDN}
		else
			get-node-list all
			for NODENAME in ${NODELIST}
			do
       	 			echo "Starting up: ${NODENAME}"
       	 			virsh start ${NODENAME}
				sleep 1
			done
		fi
	fi

	if [ ${OPTION} == "stopcluster" ]
	then
		#infrastopcluster

		get-node-list active
		for NODENAME in ${NODELIST}
		do
			echo "Shutting down: ${NODENAME}"
			ssh -i ~/.ssh/id_rsa_ocp  -o "StrictHostKeyChecking no" core@${NODENAME} sudo shutdown -h 1
			echo
		done
	fi

	if [ "${OPTION}" == "addnode" ]
	then
		# infraaddnode

		echo
                echo ">>> ADD A NEW WORKER NODE  <<<"
		
		check-cluster-state 0 api
		check-for-error-and-exit $? "Cluster is not fully operational for this operation"

		echo "NOTE: YAKKO will NOT TEST for capacity to handle this request, proceed with caution"
		echo

		WORKERNODECOUNT=1
		if [ ! -z "$2" -a ! -z "$3" -a ! -z "$4" ]
		then
			# Automation: 
			AUTOSETUP=1
			WORKERNODECOUNT=$2
			WORKERVCPUS=$3
			WORKERRAMSIZE=$4


			if [ $WORKERRAMSIZE -lt 2560 -o $WORKERRAMSIZE -gt 16384 ]
			then
				echo
				echo "ERROR: RAM size needs to be between 2560 and 16384 MB"
				echo
				exit
			fi
		else

			# For now we will use the stock configuration, add query for RAM and CPU?
			while [ 1 ]
       	         	do
       	         		echo -n "How many cores should be allocated to this node [${WORKERVCPUS}]: "
				read VALUE
				if [ ! -z "$VALUE" ]
				then
					NUMBERRE='^[0-9]+$'
					if ! [[ $VALUE =~ $NUMBERRE ]] ; then
						echo "Error: Not a number. Try again..."
						continue
					elif [ $VALUE -gt ${MAXNODEVCPUS} ]
					then
						echo "Error: Cannot assign more than ${MAXNODEVCPUS}"
						continue
					elif [ $VALUE -eq 0 ]
					then
						echo "Error: Cannot assign ZERO CPUs"
						continue
					else
						WORKERVCPUS=$VALUE
					fi
				fi
				break
			done
			echo
	
			while [ 1 ]
			do
				echo -n "How much RAM (MiB) should be allocated to this node (2560-16384MiB) [${WORKERRAMSIZE}]: "
				read VALUE
				if [ ! -z "$VALUE" ]
				then
					NUMBERRE='^[0-9]+$'
					if ! [[ $VALUE =~ $NUMBERRE ]] ; then
						echo "Error: Not a number. Try again..."
						continue
					else
						if [ $VALUE -lt 2560 -o $VALUE -gt 16384 ]
						then
							echo "RAM size needs to be between 2560 and 16384 MB"
							continue
						else
							WORKERRAMSIZE=$VALUE
						fi
					fi
				fi
				break
			done
		fi
		echo

		YAKKOSTAGE=0 # This is to artificially use the progress-stage framework
		process-stage-configureocpworkernodes progress
		if [ $? -ne 0 ]
		then		
			echo
			echo "Worker nodes were not built. Exiting..."
			echo
			exit
		fi

		approve-csrs-normal	

		trap "echo;echo \"Node [${NEWNODENAME}]  has not joined the cluster - deleting...\"; delete-kvm-machine ${NEWNODENAME}; exit" SIGINT

		echo "Node(s) ready to begin integration into the cluster. This will take a few minutes..."
		echo "To observe node status, run 'oc get nodes' on another terminal."
		echo

		while [ ! -z "${NEWNODELIST}" ]
		do 
			sleep 10

			for EACHNODE in ${NEWNODELIST}
			do
				oc get node ${EACHNODE} 2>/dev/null  | grep -v NAME | grep -v "NotReady" | grep Ready >/dev/null 2>&1
				if [ $? -eq 0 ]
				then 
					echo "Node (${EACHNODE}) has been added to the cluster and is in READY state "
					echo
					NEWNODELIST=$(echo ${NEWNODELIST} | sed -e "s/\ *${EACHNODE}//")
				fi
			done
		done 

		print-time-elapsed
		echo
	fi

	if [ "${OPTION}" == "deletenode" ]
	then
		# infradeletenode

		echo
                echo ">>> DELETE NODE FROM THE CLUSTER  <<<"

		check-cluster-state 0 api
		check-for-error-and-exit $? "Cluster is not fully operational for this operation"

		echo "Deleting a node may cause unintended consequences and prevent some workloads from"
		echo "restarting, depending on their dependencies and the resources left in the cluster"
		echo "Use at your own risk!"
		echo

		if [ ! -z "$3" ]
		then
			# Here's hoping the user knows what he's doing
			NODENAME=$3

			echo "Deleting node [${NODENAME}]"
			echo

			oc get nodes | awk '{print $1}' | grep "^${NODENAME}$"
                        [ $? -ne 0 ] && {
				echo
                        	echo "Invalid node name [${NODENAME}]. Exiting..."
				echo
				exit
			}
		else

			CURRENTNODES=$(oc get nodes | awk '{print $1}' | grep "^node-")
		
			if [ -z "${CURRENTNODES}" ]
			then
				echo "There are no worker/infra nodes defined, nothing to delete!"
				echo
				exit
			fi

			while [ 1 ]
			do
				echo "The following nodes are available for deletion: "
				for EACHNODE in ${CURRENTNODES}
				do
					echo ${EACHNODE}
				done
				echo
	
				echo -n "Enter the name of the node you want to delete from the cluster: "
				read NODENAME
	
				oc get nodes | awk '{print $1}' | grep "^${NODENAME}$"
				[ $? -eq 0 ] && break
	
				echo "Invalid node name."
			done
		fi

		# Drain the node...
		oc adm drain ${NODENAME} --force=true --ignore-daemonsets
		oc delete node ${NODENAME}

		# Delete the VM
		delete-kvm-machine ${NODENAME}

		# Update the virtual network
		echo "Restarting virtual network"
		cat ${NETWORKXML} | grep ${NODENAME} > /tmp/dhcp-yakko-line.xml #It's way too hard to pass this as an argument below!
		virsh net-update ${NETWORKNAME} delete ip-dhcp-host /tmp/dhcp-yakko-line.xml --live --config 
                check-for-error-and-exit $? "Could not restart the virtual network"
		rm /tmp/dhcp-yakko-line.xml
		sed -i "/${NODENAME}/d" ${NETWORKXML}

		#and we update the haproxy
		echo "Updating and restarting HAproxy"
		sed -i "/${NODENAME}/ d" /etc/haproxy/haproxy.cfg
                systemctl restart haproxy
                check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."
	fi

	if [ "${OPTION}" == "nodelogs" ]
	then
		#infranodelogs

		if [ ! -z "$2" ]
		then
			# Surely the user knows what he's doing...
			NODENAME=$2
		else
			pick-a-node "Select the node name whose logs you want to follow"
		fi

		echo
		echo "Displaying logs for node ["${NODENAME}"] - (CTRL-C to disconnect when done)"
		echo
		ssh -i $OCPSSHKEY core@${NODENAME}  journalctl -b -f -u crio.service
	fi

	if [ "${OPTION}" == "sshtonode" ]
	then
		#infrasshtonode

		if [ ! -z "$2" ]
		then
			# Surely the user knows what he's doing...
			NODENAME=$2
		else
			pick-a-node "Select the node you want to ssh into"
		fi
		echo
		echo "Establishing SSH session to node ["${NODENAME}"] - (CTRL-D to disconnect when done)"
		echo
		ssh -i ~/.ssh/id_rsa_ocp -o "StrictHostKeyChecking no" core@${NODENAME}
	fi

	if [ "${OPTION}" == "openaccess" ]
	then
		#infraopenaccess

		HOSTIP=$(hostname -i)

		echo
		echo ">>> ENABLE OPEN ACCESS TO OPENSHIFT <<<"
		echo

		echo "Enabling \"${OPTION}\" will permit access to your cluster from clients in your environment."
		echo "This is achieved by opening the haproxy configuration in /etc/haproxy/haproxy.cfg and by"
		echo "enabling wildcard DNS in your network configuration to provide access to all sub-domains"
		echo "created by OpenShift/Kubernetes for projects/namespaces."
		echo 
		echo "HOW \"openaccess\" WORKS ON YOUR LAN:"
		echo
		echo "   - After installation, a YAKKO cluster only listens to requests from the YAKKO host"
		echo "     on the KVM virtual network. HAproxy access will be opened to listen to requests "
		echo "     from any host (and not just the YAKKO host) via ports ports 80, 443, 6443 and 22623." 
		echo "     NOTE: You need to verify that these ports are not in use on this host!"  
		echo
		echo "   - For other clients to know of your server, you need to extend a DNS wildcard:"
		echo
		echo "     1) You can use a DNS wildcard lookup facility served from this host *if needed*."
		echo "        For home/lab purposes, DNSMASQ is a great tool with this capability. "
		echo "        YAKKO can deploy a DNS workaround on this server. OR..."
		echo 
		echo "     2) If you choose to use your own DNS facility, you need to add a wildcard pointing"
		echo "        to this host's OCP entrypoint. If you already use DNSmasq, just add this line "
		echo "        to your DNSmasq configuration (be sure to replace the IP address if not correct):"
		echo
		echo "             address=/${CLUSTERFQDN}/${HOSTIP}"
		echo

		query-user "Enable open access to your OCP cluster via HAproxy" "Y" noauto
		if [ $? -eq 0 ] 
		then
			echo "Backing up /etc/haproxy/haproxy.cfg"
			cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.cfg.bak
			for PORT in 80 443 6443 22623 
			do 
				echo "Changing access for port $PORT"
				sed -i "/    bind ${CLUSTERPROXY}:${PORT}/c\    bind :${PORT}" /etc/haproxy/haproxy.cfg
				sleep 1
			done
			echo Restarting HAPROXY...
			systemctl restart haproxy
                        check-for-error-and-exit $? "Could not start HA Proxy, the cluster cannot function without this."
			echo
		else
			echo
			echo "No changes were made. You can only access OpenShift from this server."
			echo
			exit
		fi

		systemctl status dnsmasq >/dev/null 2>&1
		if [ $? -eq 0 ] 
		then 
			echo "It appears that you are using DNSmasq in your system, so YAKKO will not attempt"
			echo "to configure your setup. You may want to use the instructions above."
		else
			echo "If you DO NOT HAVE your own DNS service, you can use this server as a DNSmasq DNS source."
			query-user "Enable DNSmasq services on this server" "N" noauto
			if [ $? -eq 0 ] 
			then
				query-user "Use [$HOSTIP] as the LAN addres for this server" "Y" noauto
				[ $? -ne 0 ] && {
					echo -n "Enter the IP address for this host on your LAN: "
					read HOSTIP
				}
				
				echo
				echo "Updating dnsmasq.conf at ${DNSMASQCONFIGFILE}"
				sleep 1
				# CAN THIS RUN ON THIS SERVER!
				{
					echo "listen-address=127.0.0.1,${HOSTIP}"
					echo "address=/apps.${CLUSTERFQDN}/${HOSTIP}"
					echo "address=/api.${CLUSTERFQDN}/${HOSTIP}"
					echo "server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
				} > ${DNSMASQCONFIGFILE}
	
				echo "Restarting NetworkManager for updated dnsmasq config"
				systemctl restart NetworkManager
				sleep 2
				check-for-error-and-exit $? "Failed to restart [NetworkManager]!!!" 
	
				echo
				echo "Ready. To test, enable [$HOSTIP] as a DNS server in a client and point your"
				echo "web browser on that client to the cluster console at: "
				echo
				echo "    $(${OCPINSTALLSOURCE}/oc whoami --show-console)"
				echo
			else
				echo
				echo "Local DNSmasq server not modified. If you run your own DNSmasq server"
				echo "use the above instructions for configuring your dnsmasq.conf."
				echo
			fi
		fi
	fi

	if [ ${OPTION} == "deletecluster" ]
	then
		# infradeletecluster
		# Danger Will Robinson!

		if  [ "$2" == "${CLUSTERNAME}" ]
		then
			echo "You have requested to DELETE the current cluster: [${CLUSTERNAME}]."
			echo
			echo -n "Please confirm by entering the cluster name again: "
			read DELETECLUSTERNAME
			if [ ${DELETECLUSTERNAME} == ${CLUSTERNAME} ]
			then
				execute-yakko-stages rollback
			else
				echo
				echo "ERROR: incorrect cluser name, delete not confirmed."
			fi
		else
			echo "ALERT: To delete cluster [${CLUSTERNAME}] and all associated ${YAKKONAME} configuration, you also need to pass the clustername" 
			echo "RUN:   $0 infra deletecluster ${CLUSTERNAME}"
			echo
		fi
	fi

	exit

}


yakko-cluster-operations() {

	# This is just nice stuff to have after the install is done
	# we're here because the user called "yakko ops"

	OPTION=$1
	echo "${YAKKOCLUSTEROPTIONS}" | grep " ${OPTION} " > /dev/null
	if [ -z "${OPTION}" -o $? -ne 0 ]
	then
		# Catchall for any other passed parameted at this point
		echo "USAGE: ${YAKKONAME} ops <OPTION> [parameters]" 
		echo
		echo "OPTION is one of:"
		echo "    - htpasswd      -> deploy local password access and a new administrator"
		echo "    - useradd       -> add a new user to local password DB"
		echo "    - userdelete    -> delete an existing user from the local password DB"
		echo "    - mastersched   -> enable/disable master scheduling"
		echo "    - nodelabel     -> Change the label of a node between worker <-> infra"
		echo "    - localregistry -> enable a local registry so you can actually use the cluster"
		echo "    - yakkotest     -> deploy the 'yakkotest' app on your cluster, to test the lot!!"
		echo
		exit
	fi


	HTPASSWDFILE=/tmp/ocp-htpasswd

	if [ ${OPTION} == "htpasswd" ]
	then
		#opshtpasswd

		echo
		echo ">>> ENABLE ADMIN and LOCAL PASSWORDS IN OPENSHIFT (HTPasswd) <<<"
		echo

		# Need htpasswd from httpd-tools
		install-package-if-missing httpd-tools 

		if [ -z "${YAKKOHTPASSWD}" ]
		then
			if [ -z "$2" ]
			then
				NEWUSER=administrator
				echo "You must enter a new administrator who will be granted cluster-admin role."
				echo -n "Enter a new admin username to add to the HTPasswd provider [administrator]: "
				read NEWUSER
			        [ -z "${NEWUSER}" ] && NEWUSER="administrator"	
			else
				NEWUSER="$2"
			fi

			echo
			echo -n "Enter password for user [$NEWUSER]: "
			read -s NEWPASSWORD
			echo
			echo -n "Retype password for confirmation: "
			read -s CONFIRMPASSWORD
			echo
			if [ "$NEWPASSWORD" != "$CONFIRMPASSWORD" ]
			then
				echo "Passwords didn't match! Exiting..."
				echo
				exit
			fi

			{
				echo "apiVersion: config.openshift.io/v1"
				echo "kind: OAuth"
				echo "metadata:"
				echo "  name: cluster"
				echo "spec:"
				echo "  identityProviders:"
				echo "  - name: Local Password"
				echo "    mappingMethod: claim"
				echo "    type: HTPasswd"
				echo "    htpasswd:"
				echo "      fileData:"
				echo "        name: htpass-secret"
			} > /tmp/oauth-config.yaml

			oc apply -f /tmp/oauth-config.yaml
			check-for-error-and-exit $? 'Could not apply OAuth Custom Resource for HTaccess (see /tmp/oauth-config.yaml)' 

			htpasswd -c -B -b ${HTPASSWDFILE} $NEWUSER $NEWPASSWORD
			oc create secret generic htpass-secret --from-file=htpasswd=${HTPASSWDFILE} -n openshift-config
			echo "YAKKOHTPASSWD=1" >> ${CLUSTERCONFIGFILE}
			sleep 3

			oc adm policy add-cluster-role-to-user cluster-admin $NEWUSER
			check-for-error-and-exit $? "Could not enable $NEWUSER as a user." 
			echo
			echo "Added [$NEWUSER] admin user with cluster-admin role successfuly"
			echo
			echo "YAKKOADMIN=${NEWUSER}" >> ${CLUSTERCONFIGFILE}

			query-user "Disable 'kubeadmin' account" Y && {
				echo "Deleting secret for 'kubeadmin' account" 
				oc --user=admin delete secret kubeadmin -n kube-system
				[ $? -eq 0 ] && echo "YAKKOADMIN=${NEWUSER}" >> ${CLUSTERCONFIGFILE}
				echo "Note that the system:admin account is still available"
			}
			echo
	
		else
			echo "Local passwords have already been enabled."
			echo
		fi
	fi

	if [ ${OPTION} == "useradd" ]
	then
		#opsuseradd

		echo
		echo ">>> ADD A LOCAL USER TO OPENSHIFT <<<"
		echo
		[ "${YAKKOHTPASSWD}" -eq 1 ] 
		check-for-error-and-exit $? "You need to first configure Local Passwords via \"YAKKONAME enable htpasswd\"" 

		if [ -z "$2" ]
		then
			echo -n "Enter the name for a new user to add to the HTPasswd provider: "
			read NEWUSER
		else
			NEWUSER="$2"
		fi
		
		echo -n "Enter password for user [$NEWUSER]: "
		read -s NEWPASSWORD
		echo
		echo -n "Retype password for confirmation: "
		read -s CONFIRMPASSWORD
		echo
		if [ "$NEWPASSWORD" != "$CONFIRMPASSWORD" ]
		then
			echo "Passwords didn't match! Exiting..."
			echo
			exit
		fi

		oc get secret htpass-secret -n openshift-config -o jsonpath={.data.htpasswd} | base64 -d > ${HTPASSWDFILE}
		htpasswd -Bb ${HTPASSWDFILE} ${NEWUSER} "${NEWPASSWORD}"
		oc patch secret htpass-secret -n openshift-config -p "{\"data\":{\"htpasswd\":\"$(base64 -w0 ${HTPASSWDFILE})\"}}"
		check-for-error-and-exit $? "Could not retrieve existing htpasswd file from the cluster" 

		oc adm policy add-cluster-role-to-user self-provisioner $NEWUSER
		check-for-error-and-exit $? "Could not assign self-provisioner role to $NEWUSER" 

		echo
		echo "Success: added user $3 and assigned self-provisioner role."
		echo "It may take a few moments before you can login."
		echo
	fi

	if [ "${OPTION}" == "userdelete" ]
	then
		#opsuserdelete

		echo
		echo ">>> DELETE AN EXISTING LOCAL USER FROM OPENSHIFT <<<"
		echo
		
		[ "${YAKKOHTPASSWD}" -eq 1 ]
                check-for-error-and-exit $? "There is no local HTPasswd configured, cannot delete anyone yet!"

                ! [ -z "$2" ]
                check-for-error-and-exit $? "you need to also pass a USERNAME for the username to delete"

		DELUSER=$2
		oc get secret htpass-secret -n openshift-config -o jsonpath={.data.htpasswd} | base64 -d > ${HTPASSWDFILE}

		cat ${HTPASSWDFILE} | grep $DELUSER > /dev/null
		if [ $? -eq 0 ]
		then
			htpasswd -D ${HTPASSWDFILE} $DELUSER
			oc patch secret htpass-secret -n openshift-config -p "{\"data\":{\"htpasswd\":\"$(base64 -w0 ${HTPASSWDFILE})\"}}"
			check-for-error-and-exit $? "Could not update password file in OCP, user not deleted"
		else
			echo "User [$DELUSER] not found in OCP, could not delete."	
		fi
		echo
	fi
		
	if [ "${OPTION}" == "localregistry" ]
	then
		#opslocalregistry

		echo
		echo ">>> ENABLE LOCAL REGISTRY IN OPENSHIFT <<<"
		echo

		query-user "Enabling local registry (images will be lost on registry restart)" "Y" noauto && {
			oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"storage":{"emptyDir":{}}}}'
			oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed"}}'
			echo

			LOCALREGISTRY=1
			echo "LOCALREGISTRY=1" >> ${CLUSTERCONFIGFILE}
		}
		
	fi

	if [ "${OPTION}" == "mastersched" ]
	then
		# opsmastersched

		echo
                echo ">>> CHANGE MASTERS' SCHEDULING STATE  <<<"
                echo

		check-cluster-state 0 api

		echo "This is an important change that may affect the behaviour of your workloads"
		echo "and is simply being provided by YAKKO as a mechanism to change new nodes quickly."
		echo "Use at your own risk!"
		echo

		oc get nodes | grep master-0 | grep worker > /dev/null 2>&1
		if [ $? -eq 0 ] #Masters are schedulable because they read 'worker'
		then
			MASTERSCHEDSTATE=true
			echo "Masters are currently >> SCHEDULABLE <<"
			echo
			if [ $(oc get nodes | grep "node-" | grep -v NotReady | grep Ready | wc -l) -eq 0 ] 
			then
				echo 
				echo "ATTENTION: There are no worker nodes available! Proceed with caution."
				echo
			fi
			query-user "Change masters to [NOT SCHEDULABLE]" Y noauto
			[ $? -eq 0 ] && NEWMASTERSCHEDSTATE=false
		else
			MASTERSCHEDSTATE=false
			echo "Masters are currently >> NOT SCHEDULABLE <<"
			echo
			query-user "Change masters to [SCHEDULABLE]" Y noauto
			[ $? -eq 0 ] && NEWMASTERSCHEDSTATE=true
		fi

		if [ ! -z "${NEWMASTERSCHEDSTATE}" ]
		then
			# Little hack...
			export KUBE_EDITOR="sed -i s+mastersSchedulable:\ ${MASTERSCHEDSTATE}+mastersSchedulable:\ ${NEWMASTERSCHEDSTATE}+"

			oc edit schedulers.config.openshift.io cluster
			[ $? -ne 0 ] && echo "This operation was not succssful"
			echo
		fi
	fi

	if [ "${OPTION}" == "nodelabel" ]
	then
		# opsnodelabel
		# This one is for fun, has a cute little hack

		echo
                echo ">>> CHANGE A NODE'S LABEL: WORKER <-> INFRA <<<"
                echo

                check-cluster-state 0 api
                check-for-error-and-exit $? "Cluster is not fully operational for this operation"

                CURRENTNODES=" $(oc get nodes | grep "^node-" | awk '{print $1}') "

                if [ -z "${CURRENTNODES}" ]
                then
                        echo "There are no worker/infra nodes defined, nothing to change!"
                        echo
                        exit
                fi

		echo "This is an important change that may affeect the behaviour of your workloads"
		echo "and is simply being provided by YAKKO as a mechanism to change new nodes quickly."
		echo "Use at your own risk!"
		echo
                echo "The following nodes are available for relabeling: "
		oc get nodes | grep "^node-" | awk '{print $1, $3}'
                echo

                while [ 1 ]
                do

                        echo -n "Enter the name of the node you want to relabel: "
                        read NODENAME
			
			echo ${CURRENTNODES} | grep ${NODENAME} > /dev/null 2>&1
			[ $? -ne 0 ] && {
				echo "Invalid node name"
				echo
				continue
			}
		break
		done

		NODELABEL=$(oc get nodes | grep ${NODENAME}" "| awk '{print $3}')

		if [ ${NODELABEL} == "worker" ]
		then
			NEWNODELABEL="infra"
		else
			NEWNODELABEL="worker"
		fi
		
		# Little hack...
		export KUBE_EDITOR="sed -i s+node-role.kubernetes.io/${NODELABEL}+node-role.kubernetes.io/${NEWNODELABEL}+"

		echo
		query-user "Change [${NODENAME}] label from [${NODELABEL}] to [${NEWNODELABEL}]" Y noauto
		if [ $? -eq 0 ]
		then
			oc edit node ${NODENAME}
			[ $? -ne 0 ] &&
				echo "This operation was not succssful"
		else
			echo "No changes were made./"
		fi
		echo
	
	fi

	if [ "${OPTION}" == "yakkotest" ]
	then
		# opsyakkotest

		echo
                echo ">>> DEPLOY YAKKO TEST ON THE CLUSTER!  <<<"
                echo

		if [ -z "${LOCALREGISTRY}" ]
		then
			echo 
			echo "Cannot deploy YAKKO test app as there is no registry defined."
			echo 'First, run "yakko ops localregistry"'
			echo
			exit
		fi

		oc new-project yakkotest
		oc new-app httpd:latest~https://github.com/ozchamo/yakko-test.git --name=yakko
		oc expose service yakko --hostname=yakkotest.apps.${CLUSTERFQDN}
		echo ${SEPARATIONLINE}
		echo
		echo
		echo "OpenShift will begin building the project"
		echo "Inspect progress by issuing 'oc get pods -n yakkotest'"
		echo
		echo "Once yakkotest is up, point your browser to: http://$(oc get routes | grep yakkotest | awk '{print $2}')"
		echo
	fi
		
	exit
}



###### STAGE PROCESSORS FOLLOW ################################################
# progress is move forwarwd, configure, install
# rollback is move back, undo, delete
###############################################################################


process-stage-libvirt() {

	[ $1 == "progress" ] && {
	
		advance-stage-progression "Libvirt package install/start" 
		# This one is mandatory so there is no && return at the end of the call
		# The thing is, if there is no KVM, there is no hope!

		#VIRTUALISATION IS MANDATORY THE FIRST TIME WE RUN THIS
		systemctl status libvirtd --no-pager > /dev/null 2>&1
		[ $? -ne 0 ] && {
			cat /proc/cpuinfo | egrep "vmx|svm" >/dev/null 2>&1
			check-for-error-and-exit $? "Virtualisation extensions are not enabled in this system!"			

			install-package-if-missing libvirt 
			#install-package-if-missing bridge-utils 
			install-package-if-missing virt-install
			install-package-if-missing qemu-kvm
			install-package-if-missing virt-top
		}
		systemctl enable libvirtd --now > /dev/null 2>&1
		systemctl status libvirtd --no-pager > /dev/null 2>&1
		check-for-error-and-exit $? "Failed to enable [libvirtd]" 

		echo "Libvirt is installed and active"

		# and just in case...
		lsmod | grep kvm >/dev/null
		check-for-error-and-exit $?  "KVM kernel modules are not loaded!"
	}

	# Nothing to rollback
	[ $1 == "rollback" ] && {
		rollback-stage-progression "Libvirt will remain installed"
	}
}


process-stage-pullsecret() {

	[ $1 == "progress" ] && {

		advance-stage-progression "Load pull secret" && return

		[ -r ${PULLSECRETFILE} ] && PULLSECRET=$(cat ${PULLSECRETFILE})

		query-user "Add a new pull secret" N
		WANTPULLSECRET=$?

		# There is no pull secret on file or user wants a new one now
		if [ -z "${PULLSECRET}" -o ${WANTPULLSECRET} -eq 0 ]
		then
			echo "A new pull secret is required."
		        echo "Please copy/paste pull secret from [ https://cloud.redhat.com/openshift/install/metal/user-provisioned ]:"
		        read PULLSECRET
		        echo $PULLSECRET > ${PULLSECRETFILE}
		fi
	}

	# Nothing to rollback - we don't want to delete the existing pull secret
	[ $1 == "rollback" ] && {
		rollback-stage-progression "Existing Pull Secret will remain in place"
	}
}


process-stage-sshclient() {

	[ $1 == "progress" ] && {

	        advance-stage-progression "SSH key configuration" && return

		query-user "Create new SSH key for node access" "Y"  && {
			#We clear a potential clash for ssh logins in .known_hosts
			sed -i "/bootstrap.${CLUSTERFQDN}/d" /root/.ssh/known_hosts > /dev/null 2>&1
			ssh-keygen -t rsa -b 4096 -N '' -f $OCPSSHKEY
		 	check-for-error-and-exit $?  "Failed to create SSH key"
			eval "$(ssh-agent -s)"
			ssh-add $OCPSSHKEY
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting ssh key and removing cluster hosts from ssh known hosts..."
		rm -r ${OCPSSHKEY} > /dev/null 2>&1
		rm -r ${OCPSSHKEY}.pub > /dev/null 2>&1

		get-node-list all
		for NODENAME in ${NODELIST}
		do
			sed -i "/${NODENAME}/d" /root/.ssh/known_hosts
		done
	}
}


process-stage-virtualnetwork() {


	[ $1 == "progress" ] && {
	
        	advance-stage-progression "Virtual Network Configuration" && return

		query-user "Configure Virtual Network" "Y" && {

			NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml
		
			echo Cleaning up network...
			virsh net-destroy ${NETWORKNAME} > /dev/null 2>&1
			virsh net-undefine ${NETWORKNAME} > /dev/null 2>&1
			
			NETWORKTYPE=1 # Query when BRIDGE is supported. Not yet ;)
			echo Only NAT is supported for now
			#if [ $NETWORKTYPE != 1 -a $NETWORKTYPE != 2 ]
			#then
			#	echo -n 'Should this network be 1.NAT or 2.BRIDGE (1 or 2)? '
			#	read NETWORKTYPE
			#fi
		
			if [ $NETWORKTYPE == 1 ] # NAT
			then
				echo "YAKKO will create all infrastructure in the ${BASENETWORK}/24 subnet with preallocated IP addresses:"
				echo Bootstrap: ${BOOTSTRAPIP}	
				echo Masters: ${MASTER0IP} ${MASTER1IP} and ${MASTER2IP}
				echo
		
				{
					echo "<network>" 
					echo "	<name>${NETWORKNAME}</name>"
		
	 				echo "	<forward mode='nat'>"
					echo "		<nat>"
					echo "			<port start='1024' end='65535'/>"
					echo "		</nat>"
					echo "	</forward>"
		
					echo "	<bridge name='virbrocp' stp='on' delay='0'/>"
		
					echo "	<domain name='${CLUSTERFQDN}' localOnly='yes'/>"
					echo "	<dns>"
					echo "		<forwarder domain='apps.${CLUSTERFQDN}' addr='127.0.0.1'/>"
					echo "		<host ip='${CLUSTERPROXY}'>"
					echo "			<hostname>api</hostname>"
					echo "			<hostname>api-int</hostname>"
					echo "		</host>"
					echo "		<host ip='${MASTER0IP}'>"
					echo " 	         	<hostname>etcd-0</hostname>"
					echo " 	         	<hostname>master-0</hostname>"
					echo "		</host>"
					echo "		<host ip='${MASTER1IP}'>"
					echo " 	         	<hostname>etcd-1</hostname>"
					echo " 	         	<hostname>master-1</hostname>"
					echo "		</host>"
					echo "		<host ip='${MASTER2IP}'>"
					echo " 	         	<hostname>etcd-2</hostname>"
					echo " 	         	<hostname>master-2</hostname>"
					echo "		</host>"
		
					# SRV Records are not required from OCP 4.4 onwards... But never mind
		
					echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-0.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
					echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-1.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
					echo " 	 	<srv service='etcd-server-ssl' protocol='tcp' domain='${CLUSTERFQDN}' target='etcd-2.${CLUSTERFQDN}' port='2380' priority='0' weight='10'/>"
					echo "	</dns>"
					echo "	<ip address='${CLUSTERPROXY}' netmask='255.255.255.0'>"
	   	 			echo "		<dhcp>"
					echo "			<range start='${BASENETWORK}.5' end='${BASENETWORK}.254'/>"
					echo "			<host mac='${BOOTSTRAPMAC}' name='bootstrap.${CLUSTERFQDN}' ip='${BOOTSTRAPIP}'/>"
					echo " 			<host mac='${MASTER0MAC}' name='master-0.${CLUSTERFQDN}' ip='${MASTER0IP}'/>"
					echo " 			<host mac='${MASTER1MAC}' name='master-1.${CLUSTERFQDN}' ip='${MASTER1IP}'/>"
					echo " 			<host mac='${MASTER2MAC}' name='master-2.${CLUSTERFQDN}' ip='${MASTER2IP}'/>"
					echo "		</dhcp>"
					echo "	</ip>"
					echo "</network>"
		
				} > $NETWORKXML
			fi

			if [ ${NETWORKTYPE} == 2 ] # BRIDGED
			then
				# All virtual machines will have LAN IP Addresses
				echo ONE DAY...
			fi
			
			echo Defining network at $NETWORKXML
			virsh net-define --file $NETWORKXML
			check-for-error-and-exit $? "Defined inactive networks are: $(virsh net-list --inactive)"
			
			echo Setting network to start on boot...
			virsh net-autostart ${NETWORKNAME}
			check-for-error-and-exit $? "Could not configure virtual network for auto-start"
		}
		echo "Re/starting network to ensure it is operational..."
		virsh net-destroy ${NETWORKNAME} 2>/dev/null
		virsh net-start ${NETWORKNAME}
		check-for-error-and-exit $? "Could not start virtual network"
		echo "Virtual network is up"
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting virtual network configuration"
		virsh net-destroy ${NETWORKNAME} > /dev/null 2>&1
		virsh net-undefine ${NETWORKNAME} > /dev/null 2>&1

	}
}


process-stage-dns() {


	[ $1 == "progress" ] && {
	
        	advance-stage-progression "DNS Configuration" && return

		query-user "Configure DNS for KVM network (dnsmasq/NetworkManager)" "Y" && {

			systemctl status dnsmasq >/dev/null 2>&1
			if [ $? -eq 0 ]
			then
				# DNSMASQ is enabled on this host, we should use this instead of NetworkManager plugin
				# But, this is dangerous, so we have to leave this one to the ADMIN

				echo "YAKKO has detected that you are not using the dnsmasq plugin for NetworkManager"
				echo "and instead you are using standard DNSMASQ."
				echo
				echo "You will need to add these two addresses to your DNSMASQ configuration before continuing"
				echo "upon which ${YAKKONAME} will test the DNS of your system before continuing"
				echo
				echo "	server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
				echo "	address=/apps.${CLUSTERFQDN}/${CLUSTERPROXY}"
				echo
				query-user "Confirm that DNSMASQ has been configured and restarted" "Y" noauto
				echo
			else
				echo Configuring dnsmask plugin in NETWORKMANAGER
				# CHANGE TO END USER SYSTEM HERE
				cat /etc/NetworkManager/NetworkManager.conf | grep "\[main\]" > /dev/null 2>&1
				[ $? -ne 0 ] && echo '\[main\]' >> /etc/NetworkManager/NetworkManager.conf
	
				cat /etc/NetworkManager/NetworkManager.conf | grep "dns = dnsmasq" > /dev/null 2>&1
				[ $? -ne 0 ] && sed -i.bak '/\[main\]/ a dns = dnsmasq' /etc/NetworkManager/NetworkManager.conf
	
				rm /etc/NetworkManager/dnsmasq.d/${YAKKONAME}* 2>/dev/null #Deleting old entries
		
				{
					echo "server=/${CLUSTERFQDN}/${CLUSTERPROXY}"
					echo "address=/apps.${CLUSTERFQDN}/${CLUSTERPROXY}"
				} > ${DNSMASQCONFIGFILE}
		
				systemctl restart NetworkManager
				check-for-error-and-exit $? "Could not restart NetworkManager"

				# Trying to see of we can address the systemd-resolved changes in Fedora 33
				cat /etc/resolv.conf | grep "nameserver 127.0.0.53"
				if [ $? -eq 0 ]
				then	
					# CHANGE TO END USER SYSTEM HERE

					# We need to add after [Resolve]
					# DNS=127.0.0.1
					# Domains=~${CLUSTERDOMAIN}
					#to /etc/systemd/resolved.conf
					echo
					echo "ATTENTION: This system is using systemd-resolved. YAKKO needs to add a DNS stub in /etc/systemd/resolved.conf"

					cat /etc/systemd/resolved.conf | grep "Domains=~${CLUSTERDOMAIN}" > /dev/null 2>&1
					[ $? -ne 0 ] && sed -i.${YAKKONAME} "/\[Resolve\]/ a Domains=~${CLUSTERDOMAIN}" /etc/systemd/resolved.conf

					cat /etc/systemd/resolved.conf | grep "DNS=127.0.0.1" > /dev/null 2>&1
					[ $? -ne 0 ] && sed -i.${YAKKONAME} "/\[Resolve\]/ a DNS=127.0.0.1" /etc/systemd/resolved.conf

					systemctl restart systemd-resolved.service
					sleep 3 # This sometimes takes a bit to revive
				fi
			fi

			echo
			echo "DNS test - from Virtual Network ${BASENETWORK}.0:"

			host api-int.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve api-int.${CLUSTERFQDN} on ${BASENETWORK}"

			host etcd-0.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-0.${CLUSTERFQDN} on ${BASENETWORK}"

			host etcd-1.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-1.${CLUSTERFQDN} on ${BASENETWORK}"

			host etcd-2.${CLUSTERFQDN} ${CLUSTERPROXY} | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-2.${CLUSTERFQDN} on ${BASENETWORK}"

			host -t srv _etcd-server-ssl._tcp.${CLUSTERFQDN} ${CLUSTERPROXY}
			check-for-error-and-exit $? "Could not resolve etcd-server-ssl.${CLUSTERFQDN} on ${BASENETWORK}"
				
			echo
			echo "DNS test - from the host:"

			# Note - before Fedora 33 these tests were run with 127.0.0.1
			# Then came systemd.resolved.conf and things needed to be "updated"
			# So now, we need to add to /etc/systemd/resolvd.conf the following
			#	DNS=127.0.0.1
			#	Domains=~${CLUSTERDOMAIN}
			# and... still trying to fix it
 
			host api.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve api-int on 127.0.0.1"

			host etcd-0.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-0 on 127.0.0.1"

			host etcd-1.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-1 on 127.0.0.1"

			host etcd-2.${CLUSTERFQDN} 127.0.0.1 | grep "has address"
			check-for-error-and-exit $? "Could not resolve etcd-2 on 127.0.0.1"

			host testing.apps.${CLUSTERFQDN} 127.0.0.1
			check-for-error-and-exit $? "Could not resolve testing.apps on 127.0.0.1"
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting DNS configuration and restarting"
		rm ${DNSMASQCONFIGFILE} > /dev/null 2>&1
		mv /etc/systemd/resolved.conf.${YAKKONAME} /etc/systemd/resolved.conf >/dev/null 2>&1
	}
}

	
process-stage-loadbalancer() {

	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure Load Balancer "  && return

		query-user "Configure Load Balancer (HA Proxy) for cluster bootstrap and operation" "Y" && {

			install-package-if-missing haproxy
	
			cat /etc/httpd/conf/httpd.conf | grep "^Listen 80" >/dev/null 2>&1
			[ $? -eq 0 ] && {
				echo "ATTENTION: HAPROXY needs to run on port 80. Currently, port 80 is marked for listening by httpd."
				query-user "Disable port 80 on httpd" "Y" noauto
				if [ $? -eq 0 ]
				then		
					# CHANGE TO END USER SYSTEM HERE
					sed -i "/^Listen 80/c\# Listen 80" /etc/httpd/conf/httpd.conf  2>/dev/null
				else
					echo
					echo "ERROR: Cannot continue until PORT 80 is freed up for HAPROXY. Fix and come back! Exiting..."
					echo
					exit
				fi
			}
	
			echo Creating the HA Proxy Config...
			echo
			
			{
				# SET UP THE PROXY ON THE VIRTUAL NETWORK - FOR THE HOST

				echo "listen ${CLUSTERNAME}-api-server-6443"
				echo "    bind ${CLUSTERPROXY}:6443"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0 ${MASTER0IP}:6443 check inter 1s"
				[ ${MASTERNODECOUNT} -gt 1 ] && {
					echo "    server master-1 ${MASTER1IP}:6443 check inter 1s"
					echo "    server master-2 ${MASTER2IP}:6443 check inter 1s"
				}
				echo "    server bootstrap ${BOOTSTRAPIP}:6443 check inter 1s"

				echo 
				echo "listen ${CLUSTERNAME}-machine-config-server-22623"
				echo "    bind ${CLUSTERPROXY}:22623"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0 ${MASTER0IP}:22623 check inter 1s"
				[ ${MASTERNODECOUNT} -gt 1 ] && {
					echo "    server master-1 ${MASTER1IP}:22623 check inter 1s"
					echo "    server master-2 ${MASTER2IP}:22623 check inter 1s"
				}
				echo "    server bootstrap ${BOOTSTRAPIP}:22623 check inter 1s"
				echo 

				echo "listen ${CLUSTERNAME}-ingress-router-80"
				echo "    bind ${CLUSTERPROXY}:80"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0 ${MASTER0IP}:80 check inter 1s"
				[ ${MASTERNODECOUNT} -gt 1 ] && {
					echo "    server master-1 ${MASTER1IP}:80 check inter 1s"
					echo "    server master-2 ${MASTER2IP}:80 check inter 1s"
				}
				echo "    # addingressrouternode80"

				echo 
				echo "listen ${CLUSTERNAME}-ingress-router-443"
				echo "    bind ${CLUSTERPROXY}:443"
				echo "    mode tcp"
				echo "    balance source"
				echo "    server master-0 ${MASTER0IP}:443 check inter 1s"
				echo "    server master-1 ${MASTER1IP}:443 check inter 1s"
				echo "    server master-2 ${MASTER2IP}:443 check inter 1s"
				echo "    # addingressrouternode443"
			} > /etc/haproxy/haproxy.cfg

			setsebool -P haproxy_connect_any 1
			systemctl --now enable haproxy
			check-for-error-and-exit $? "Could not restart haproxy/loadbalancer"
			systemctl status haproxy --no-pager
		
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting and stopping Load Balancer service"
		systemctl stop haproxy
		rm /etc/haproxy/haproxy.cfg > /dev/null 2>&1
	}
}


process-stage-downloadocpbinaries() {

	[ $1 == "progress" ] && {

        	advance-stage-progression "Obtain OCP binaries (Installer and RHCOS)"  && return

		# This is the directory that the web server will run from
		[ ! -d $IMAGEREPO ] && mkdir -p $IMAGEREPO > /dev/null 2>&1
		cd $IMAGEREPO

		if [ ! -d "$OCPGETCLIENTVERSION"  ]
		then
			# Note that this script bundles your client and RHCOS dependencies under the client version number
			# we treat bad errors here differently to try to avoid repeating entire downloads

			mkdir $OCPGETCLIENTVERSION > /dev/null 2>&1
			cd $OCPGETCLIENTVERSION 
			echo "Getting the OCP installer (for version $OCPGETCLIENTVERSION) --> $PWD"

			# DOWNLOAD CLIENT STUFF FIRST (as of 4.6 it is common to all versions)
			wget $OCPDOWNLOADCLIENT/openshift-install-linux.tar.gz -O - | tar xz
			[ $? -ne 0 ] && { "echo Error downloading *openshift-installer*, exiting..."; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 

			echo "Getting the OCP client -> $PWD"
			wget $OCPDOWNLOADCLIENT/openshift-client-linux.tar.gz -O - | tar xz 
			[ $? -ne 0 ] && { "echo Error downloading *openshift-client*, exiting..."; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
		
			echo "Getting RHCOS installer files... -> $PWD"

			if [ $(echo ${OCPGETCLIENTVERSION} | cut -c3) -ge 6 ]
			then
		
				##### KERNEL
				wget $OCPDOWNLOADIMAGE/rhcos-live-kernel-x86_64
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
			
				##### INITRAMFS
				wget $OCPDOWNLOADIMAGE/rhcos-live-initramfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
		
				##### ROOTFS
				wget $OCPDOWNLOADIMAGE/rhcos-live-rootfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
		
				##### METAL
				wget $OCPDOWNLOADIMAGE/rhcos-metal.x86_64.raw.gz
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-metal*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
				
			else # Version 4.5 or earlier
		
				##### KERNEL
				wget $OCPDOWNLOADIMAGE/rhcos-installer-kernel-x86_64
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-kernel*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
			
				### INITRAMFS
				wget $OCPDOWNLOADIMAGE/rhcos-installer-initramfs.x86_64.img
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-initramfs*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
		
				##### METAL
				wget $OCPDOWNLOADIMAGE/rhcos-metal.x86_64.raw.gz
				[ $? -ne 0 ] && { echo 'Error downloading *rhcos-metal*, exiting...'; cd ..; rm -rf ${OCPGETCLIENTVERSION}; exit; } 
			fi
		else
			echo "OCP Version $OCPGETCLIENTVERSION is already downloaded..."
		fi
	
		cd ${YAKKOSETUPDIR}

		# We remove the CLIENT word to make it less confusing if someone reads the ${CLUSTERCONFIGFILE} file
		OCPINSTALLVERSION=$OCPGETCLIENTVERSION
		echo OCPINSTALLVERSION=${OCPGETCLIENTVERSION} >> ${CLUSTERCONFIGFILE}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Downloaded binaries will remain in place"
	}
}


process-stage-httpserver() {

	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure HTTP server for installation of all cluster components"  && return

		query-user "Configure and enable HTTP Server (port 8080 in virtual network) for install on this host" "Y" && {

			# Now that we know what we are running up, we can set the directory to provide the sources
			# From the below dir, things will get cookin'
			OCPINSTALLSOURCE=$IMAGEREPO/$OCPINSTALLVERSION
			echo "OCP will be made available by HTTP server from directory $OCPINSTALLSOURCE"
			echo
	
			install-package-if-missing httpd

			echo '<H1>YAKKO WEB SERVER is working!</H1>' > $IMAGEREPO/index.html # to have a test file there...
		
			{
				echo "Listen ${WEBSERVERIP}:${WEBSERVERPORT}"
				echo "<VirtualHost ${WEBSERVERIP}:${WEBSERVERPORT}>"
				echo "	DocumentRoot ${IMAGEREPO}"
	   	 		echo "	<Directory ${IMAGEREPO}>"
	   	    		echo "		Options Indexes FollowSymLinks"
	   	    		echo "		Require all granted"
	   	    		echo "		AllowOverride None"
	   	 		echo "	</Directory>"
				echo "</VirtualHost>"
		
			} > /etc/httpd/conf.d/ocp-build.conf
		
			# Figure out which of these are required
			# and needed to survive a reboot...
			chcon  --user system_u --type httpd_sys_content_t -Rv $IMAGEREPO
			semanage fcontext -a -t httpd_sys_content_t "$IMAGEREPO(/.*)?"
			restorecon -Rv $IMAGEREPO

			# We disable port 80 since we know it cannot be served via httpd
			sed -i "/^Listen 80/c\# Listen 80" /etc/httpd/conf/httpd.conf  2>/dev/null
	
			systemctl restart httpd
			check-for-error-and-exit $? "Could not start HTTPD server"
			systemctl enable httpd

			echo "OCPINSTALLSOURCE=$OCPINSTALLSOURCE" >> $CLUSTERCONFIGFILE
		}
	}

	[ $1 == "rollback" ] && {
		echo "Deleting web server for install on KVM network port 8080"
		rm /etc/httpd/conf.d/ocp-build.conf >/dev/null 2>&1
		rollback-stage-progression "Webserver will remain running when active"
	}
}


process-stage-changefirewall() {

	#If using a firewall on host, don't forget to allow connections to these ports on IP ${CLUSTERPROXY}: 6443, 22623, 80 and 443.

	[ $1 == "progress" ] && {

        	advance-stage-progression "Configure Firewall" && return

		firewall-cmd --state >/dev/null 2>&1
		if [ $? -eq 252 ]
		then
			echo "Firewall is not running. Configuration is not required."
		else
			query-user "Change Firewall rules" "Y" && { 

				echo "Changing firewall port 80/tcp access"
				firewall-cmd --add-port=80/tcp
				firewall-cmd --zone=libvirt --add-port=80/tcp

				echo "Changing firewall port 8080/tcp access"
				firewall-cmd --add-port=8080/tcp
				firewall-cmd --zone=libvirt --add-port=8080/tcp

				echo "Changing firewall port 9090/tcp access (COCKPIT)"
				firewall-cmd --add-port=9090/tcp
				firewall-cmd --zone=libvirt --add-port=9090/tcp

				echo "Changing firewall port 443/tcp access"
				firewall-cmd --add-port=443/tcp
				firewall-cmd --zone=libvirt --add-port=443/tcp

				echo "Changing firewall port 6443/tcp access"
				firewall-cmd --add-port=6443/tcp
				firewall-cmd --zone=libvirt --add-port=6443/tcp

				echo "Changing firewall port 22623/tcp access"
				firewall-cmd --add-port=22623/tcp
				firewall-cmd --zone=libvirt --add-port=22623/tcp

				echo "Changing firewall port 22623/udp access"
				firewall-cmd --add-port=22623/udp
				firewall-cmd --zone=libvirt --add-port=22623/udp
		}
		fi	
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Firewall will remain unchanged - ports stay open"
	}
}


process-stage-generateocpinstallerconfig() {

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP Configuration for Installation"  && return

		query-user "Generate OCP cluster manifests and ignition files required for cluster bootstrap" "Y" && {
	
			echo Writing "ocp-setup-env" script for administration. Run \"source ${YAKKOSETUPDIR}/ocp-setup-env\" to load post-install...
			{
				echo "PATH=\$PATH:${OCPINSTALLSOURCE}" 
				echo export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
			}  > ocp-setup-env
			chmod +x ocp-setup-env

			# And we do this for the config file too, which is for the system
			{
				echo "PATH=\$PATH:${OCPINSTALLSOURCE}" 
				echo export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
			}  >> ${CLUSTERCONFIGFILE}

			#And we set KUBECONFIG from here on too...
                        export KUBECONFIG=${CLUSTERSETUPDIR}/auth/kubeconfig
	
			# We load/reload, in case there was an interrupt to the AUTO setup and these values were released
			SSHPUBKEY=$(cat $OCPSSHKEY.pub)
			PULLSECRET=$(cat ${PULLSECRETFILE})

			# Check if HyperThreading is enabled, just in case
			CORECOUNT=$(less /proc/cpuinfo | grep cores | uniq | awk '{print $4}')
			THREADCOUNT=$(nproc)

			echo "The server has [$CORECOUNT] CPU cores and [$THREADCOUNT] threads"

			if [ ${CORECOUNT} -eq ${THREADCOUNT} ]
			then
				# No HT
				HYPERTHREADING=Disabled
			elif [ $((${CORECOUNT}*2)) -eq ${THREADCOUNT} ]
			then
				# HT is on
				HYPERTHREADING=Enabled
			else
				echo "CANNOT TELL IF HYPER-THREADING IS ENABLED, ASSUMING IT IS NOT"
				HYPERTHREADING=Disabled
			fi

			echo
			echo "Generating INSTALL CONFIG file..."
			
			{
				echo "apiVersion: v1"
				echo "baseDomain: ${CLUSTERDOMAIN}"
				echo "compute:"
				echo "- hyperthreading: ${HYPERTHREADING}"
				echo "  name: worker"
				echo "  replicas: 0"
				echo "controlPlane:"
				echo "  hyperthreading: ${HYPERTHREADING}"
				echo "  name: master"
				echo "  replicas: 3"
				echo "metadata:"
				echo "  name: ${CLUSTERNAME}"
				echo "networking:"
				echo "  clusterNetwork:"
				echo "  - cidr: 10.128.0.0/14 "
				echo "    hostPrefix: 23"
				echo "  networkType: OpenShiftSDN"
				echo "  serviceNetwork:"
				echo "  - 172.30.0.0/16"
				echo "platform:"
				echo "  none: {} "
				echo "fips: false "
				echo "pullSecret: '$PULLSECRET' "
				echo "sshKey: '$SSHPUBKEY'"
		
			} > ${CLUSTERSETUPDIR}/install-config.yaml
	
			# we make a copy for later review as this gets deleted by the create-manifests stage
			cp ${CLUSTERSETUPDIR}/install-config.yaml ${CLUSTERSETUPDIR}/install-config.yaml.original
	
			echo
			echo Creating manifests...
			${OCPINSTALLSOURCE}/openshift-install create manifests --dir=${CLUSTERSETUPDIR}
			check-for-error-and-exit $? "Could not create OCP manifests"

			if [ ${WORKERNODECOUNT} -gt 0 ]
			then
				# There are worker nodes to be built, so masters will become non-schedulable
				sed -i -r 's/(mastersSchedulable: ).*/\1False/' $CLUSTERSETUPDIR/manifests/cluster-scheduler-02-config.yml
			fi
		
			echo
			echo Creating OCP Cluster ignition files required for node configuration
			$OCPINSTALLSOURCE/openshift-install create ignition-configs --dir=$CLUSTERSETUPDIR
			check-for-error-and-exit $? "Could not create OCP ignition files"
			cp $CLUSTERSETUPDIR/*.ign $IMAGEREPO
			chmod 644 $IMAGEREPO/*.ign
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting cluster ignition and configuration files"
		rm ocp-setup-env > /dev/null 2>&1
		rm ${CLUSTERSETUPDIR}/install-config.yaml  > /dev/null 2>&1
		rm ${CLUSTERSETUPDIR}/install-config.yaml.original  > /dev/null 2>&1
		rm $IMAGEREPO/*ign  > /dev/null 2>&1
	}
}


process-stage-configurebootstrapnode() {

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Bootstrap Host Configuration" && return

		query-user "Configure OCP bootstrap VM host" "Y" && 
			# Bootstrap node is MAC address is the first to be defined 
			build-ocp-node bootstrap ${BOOTSTRAPMAC} 2 4096 20 bootstrap.ign
			check-for-error-and-exit $? "Could not build VM for node [bootstrap]"
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting bootstrap node"
		for BOOTSTRAPNODE in $(virsh list --all --name | grep "bootstrap")
                do
			delete-kvm-machine ${BOOTSTRAPNODE}
                done
	}
}


process-stage-configureocpmasternodes() {

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Master Nodes Configuration"  && return

		query-user "Configure OCP master VM hosts" "Y" && {

			build-ocp-node master-0 ${MASTER0MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
			check-for-error-and-exit $? "Could not build VM for node [master-0]"

			[ ${MASTERNODECOUNT} -gt 1 ] && {
				# It's either 1 or 3 nodes, never 2 AFAWK in 2020

				build-ocp-node master-1 ${MASTER1MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
				check-for-error-and-exit $? "Could not build VM for node [master-1]"

				build-ocp-node master-2 ${MASTER2MAC} ${MASTERVCPUS} ${MASTERRAMSIZE} ${MASTERDISKSIZE} master.ign
				check-for-error-and-exit $? "Could not build VM for node [master-2]"
			}
		}

	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting OCP master nodes"
		for MASTERNODE in $(virsh list --all --name | grep "master-")
                do
			delete-kvm-machine ${MASTERNODE}
                done
	}
}


process-stage-configureocpworkernodes() {

	[ $1 == "progress" ] && {

                advance-stage-progression "KVM Worker Node Configuration"  && return

		NODESTOBUILD=${WORKERNODECOUNT}

		if [ $NODESTOBUILD -eq 0 ]
		then
			echo "No Worker nodes were requested. Worker nodes can be added later by calling: "
			echo "      yakko infra addnode"
		else
			query-user "Configure OCP worker VM node(s)" "Y" 
			if [ $? -eq 0 ]
			then
				while [ $NODESTOBUILD -ne 0 ]
				do
					((NODESTOBUILD--))
       	                		((NODECOUNT++))
       	                	 	sed -i "/NODECOUNT=.*/c\NODECOUNT=${NODECOUNT}" ${CLUSTERCONFIGFILE} 2>/dev/null
		
       			               	NEWNODENAME=node-${NODECOUNT}
					NEWNODELIST="${NEWNODELIST} ${NEWNODENAME}"
		
					build-ocp-node ${NEWNODENAME} auto ${WORKERVCPUS} ${WORKERRAMSIZE} ${WORKERDISKSIZE} worker.ign
					check-for-error-and-exit $? "Could not build VM for node [${NEWNODENAME}]"
				done
			fi
		fi
	}     

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Deleting OCP worker nodes"

		# Here's a tricky one since this function can be used during additional node build
		# or during a complete "deletecluster"
		# When it's the latter, we know that the DELETECLUSTERNAME must have the clustername set
		if [ "${DELETECLUSTERNAME}" == "${CLUSTERNAME}" ]
		then
			# Delete ALL worker nodes
                	for NODETODELETE in $(virsh list --all --name | grep "node-")
                	do
				delete-kvm-machine ${NODETODELETE}
			done
		else
			# Delete nodes just added now with addnode
                	for NODETODELETE in ${NEWNODELIST} 
                	do
				delete-kvm-machine ${NODETODELETE}
			done
		fi
	}
}


process-stage-startocpbootstrap() {

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP Cluster Bootstrap"  && return

		query-user "Start/continue OCP Cluster bootstrap" "Y" && {
	
			echo You can observe the output of the bootstrap node at this stage by issuing:
			echo ssh -i $OCPSSHKEY core@bootstrap.${CLUSTERFQDN} "sudo journalctl -b -f -u bootkube.service"
			echo 
	
			while [ 1 ]
			do
				$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for bootstrap-complete
	
				if [ $? -eq 0 ]
				then
					#the wait-for bootstrap-complete was successful
					virsh list | grep bootstrap.${CLUSTERFQDN} > /dev/null 2>&1
					if [ $? -eq 0 ]
					then
						delete-kvm-machine bootstrap.${CLUSTERFQDN}

						# Now we delete the boostrap from the haproxy!!!
						cat /etc/haproxy/haproxy.cfg | grep -v bootstrap > /etc/haproxy/haproxy.cfg.nobootstrap
						rm -f /etc/haproxy/haproxy.cfg
						mv /etc/haproxy/haproxy.cfg.nobootstrap /etc/haproxy/haproxy.cfg; 
						systemctl restart haproxy
					fi
					break
				else
					echo
					echo "The bootstrap process doesn't appear to have completed successfully. "
					echo "This process downloads a lot of images from quay.io and can take a long time."
					echo
					echo    "Press <ENTER> to re-issue this stage (wait-for bootstrap-complete) and give it some more time, OR... "
					echo -n "Press <CTRL-C> to abort this install and examine then rerun install and return to this point"
					read CONTINUE
					$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for bootstrap-complete
					echo
				fi
			done
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "OCP boostrap stage"
	}
}


process-stage-approvecsrs() {

	[ $1 == "progress" ] && {

                advance-stage-progression "CSR Background Approval"  && return

		query-user "Approve pending/recurring CSRs" "Y" && {

			CSRAPPROVALPID=0
	
			if [ $CSRAPPROVALPID -eq 0 ]
			then
				# running oc here is a little trickier as this gets forked off, so we test for it before
				[ -x ${OCPINSTALLSOURCE}/oc ] 
				check-for-error-and-exit $? "Cannot process CSRs as this stage cannot execute command ${OCPINSTALLSOURCE}/oc"

				# This runs in the backgound approving certificates as they come...
				{
					trap "echo; echo 'CSR Approvals (oc get csr) stopped...'; exit" SIGQUIT
		
					while [ 1 ] 
					do
						sleep 10
						${OCPINSTALLSOURCE}/oc get csr 2>/dev/null | grep Pending | awk '{ print $1 }' | xargs ${OCPINSTALLSOURCE}/oc adm certificate approve > /dev/null 2>&1
					done
				} &
				CSRAPPROVALPID=$!
			fi
		
			# monitoring the output through the bootstrap requires not deleting it...
			trap 'kill -s SIGQUIT $CSRAPPROVALPID ; sleep 2; echo "Shutting down, please wait..."; sleep 20; exit' SIGINT
		}
	}		

	[ $1 == "rollback" ] && {
		rollback-stage-progression "CSR approvals"
		kill -9 $CSRAPPROVALPID > /dev/null 2>&1
	}
}


process-stage-reduceprometheusmemory() {

	[ $1 == "progress" ] && {

                advance-stage-progression "Prometheus Memory Footprint"  && return

		query-user "Reduce Prometheus pod memory allocation" "Y" && {

			PROMETHEUSPID=0

			if [ $PROMETHEUSPID -eq 0 ]
			then
				{ 
					echo "prometheusK8s:" 
					echo "  resources:" 
					echo "    requests:"
   		   			echo "      memory: 256Mi"
				} > $CLUSTERSETUPDIR/prometheus-config.yaml
		
				sleep 20 # Seen issues before...
				${OCPINSTALLSOURCE}/oc create configmap cluster-monitoring-config --from-file=config.yaml=${CLUSTERSETUPDIR}/prometheus-config.yaml -n openshift-monitoring
			
				{
					trap "echo; echo 'Prometheus pods not deleted for resizing (oc delete pod prometheus-k8s-* -n openshift-monitoring)'; exit" SIGQUIT
					sleep 30 #This is what the recipe suggested...
		
					while [ 1 ] 
					do
						${OCPINSTALLSOURCE}/oc get pods -n openshift-monitoring 2>/dev/null | grep "prometheus-k8s" > /dev/null 2>&1
						[ $? -eq 0 ] && break

						sleep 15
					done
		
					sleep 10
					echo
					echo "Deleting Prometheus pods for memory reconfiguration"
					${OCPINSTALLSOURCE}/oc delete pod prometheus-k8s-0 -n openshift-monitoring
					${OCPINSTALLSOURCE}/oc delete pod prometheus-k8s-1 -n openshift-monitoring
		
				} &
				PROMETHEUSPID=$!
			fi
		
			# monitoring the output through the bootstrap requires not deleting it...
			trap 'kill -s SIGQUIT $PROMETHEUSPID; sleep 2; echo "Shutting down prometheus memory reduction (NOT DONE), please wait..."; sleep 20; exit' SIGINT
		
		}
	}	

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Prometheus memory changes"
		kill -9 $PROMETHEUSPID > /dev/null 2>&1
		rm $CLUSTERSETUPDIR/prometheus-config.yaml >/dev/null 2>&1
	}
}


process-stage-waitforocpinstalltocomplete() {

	[ $1 == "progress" ] && {

                advance-stage-progression "OCP - Complete Installation"  && return

		query-user "Wait for OCP install to complete" "Y" && {

			echo Some useful commands while waiting:
			echo "- source ocp-setup-env  (for command line access to oc as setup)"
			echo "- tail -f $CLUSTERSETUPDIR/.openshift_install.log"
			echo "- oc get co  (To check how operators are progressing...)"
			echo "- oc get nodes  (always good to see if your cluster has all the nodes it should...)"
			echo "- oc adm top nodes (to see how your nodes are performing based on their CPU/RAM constraints..."
			echo
		
			$OCPINSTALLSOURCE/openshift-install --dir=$CLUSTERSETUPDIR wait-for install-complete 
			OCPINSTALLCODE=$?
			
			# Stop background "assistants"
			kill -s SIGQUIT $CSRAPPROVALPID $PROMETHEUSPID >  /dev/null 2>&1
			sleep 15

			echo
			echo ${SEPARATIONLINE}
			echo
			print-in-green  FINISHED OCP INSTALLATION - $(date)
			print-time-elapsed
			
		
			if [ $OCPINSTALLCODE -ne 0 ]
			then
				echo 
				echo The OCP Installer exited with code [ $OCPINSTALLCODE ]
				echo Cluster has $(${OCPINSTALLSOURCE}/oc get nodes | egrep "worker|master" | wc -l) nodes and $(${OCPINSTALLSOURCE}/oc get co | awk '{ print $3 }' | grep True | wc -l) operators up 
			else
				echo
				print-in-green "IMPORTANT:"
				print-in-green "	- you DO NOT have a registry -> yakko ops localregistry"
				print-in-green "	- you cannot access the cluster from another computer -> yakko ops openaccess"
				print-in-green "	- you have no user DB-> yakko ops htpasswd administrator &  yakko ops useradd <user>"
				print-in-green ${SEPARATIONLINE}
			fi

			# We write the first time we believe the cluster was up, for reference
			# It also let's us know that there is no further building possible
			echo CLUSTERCOMPLETE=\"exit code [${OCPINSTALLCODE}] at [$(date)]\" >> ${CLUSTERCONFIGFILE}
	
			# This is my tab keeper, starting on 24/11/2020
			# to keep track of how many clusters I've built on my big box
			if [ "$(hostname)" == "terminus" ]
			then
				echo "Cluster [${CLUSTERNAME}] built on [$(date)] - Masters: ${MASTERNODECOUNT} Workers: ${WORKERNODECOUNT}" >> /YAKKO-TALLY-$(hostname)
			fi
			echo
			
			check-cluster-state 1
		}
	}

	[ $1 == "rollback" ] && {
		rollback-stage-progression "installation of OCP cluster ${CLUSTERNAME}"	
	}
}


process-stage-continue-clusterconfiguration() {

	[ $1 == "progress" ] && {

        	advance-stage-progression "Continue Cluster Configuration"

		if [ ! -z "${CLUSTERCOMPLETE}" ]
		then	
			#if there was an install code registered in ${CLUSTERCONFIGFILE} file then the installer did all it could.
			check-cluster-state 1
			exit
		fi

		echo
		query-user "Attempt AUTOMATIC configuration of cluster from this point" "Y" noauto
		if [ $? -eq 0 ]
		then 
			AUTOSETUP=1
		else
			echo
			query-user "MANUAL CONFIGURATION: Resume where you left off (\"y\") or Start from the begining (\"n\")" "Y" noauto
			if [ $? -ne 0 ]
			then
				YAKKOSTAGE=0
			fi
		fi
	}	

	# NOTE: THIS STAGE MUST PRECEDE execute-yakko-stages
	# 	SEE MAIN AT BOTTOM

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Cluster configuration"
	}
}


process-stage-gatherclusterconfiguration() {

	[ $1 == "progress" ] && {

        	advance-stage-progression "Gather Cluster Configuration information"

		# A cluster config does not exist - this should be the first run
		
		# Some of these are more "global" in nature so we store them in ${YAKKODEFAULTS}
		# (which was separate functionality in earlier versions)

	
		### QUESTION: Cluster name  ## Not stored in YAKKO defaults

		while [ 1 ]
		do
			if [ ! -z "${CLUSTERNAME}" ]
			then
				echo -n  "Enter the name of the OpenShift cluster to create (\"${CLUSTERNAME}\"): "
			else
				echo -n "Enter the name of the OpenShift cluster to create: "
			fi
			read RESPONSE

			if [ -z "${RESPONSE}" -a ! -z "${CLUSTERNAME}" ]
			then
				echo "Cluster [${CLUSTERNAME}] will be created"
				break
			fi
	
			if [[ ${RESPONSE} =~ ^[a-z0-9]*$ ]]
			then
				CLUSTERNAME=${RESPONSE}
				break
			else
				echo "Invalid cluster name. Please use lower-case characters and numbers only."
			fi
		done
	
		CLUSTERSETUPDIR=${YAKKOSETUPDIR}/install-${CLUSTERNAME}
		mkdir $CLUSTERSETUPDIR > /dev/null 2>&1
		NETWORKNAME=net-ocp-${CLUSTERNAME}
		NETWORKXML=$CLUSTERSETUPDIR/${NETWORKNAME}.xml

		### QUESTION: domain name ## Stored in YAKKO defaults
       		echo
		echo -n "Enter the DOMAIN name you wish to setup your cluster under (\"${CLUSTERDOMAIN}\"): "
       	 	read RESPONSE
		[ ! -z "$RESPONSE" ] && CLUSTERDOMAIN=$RESPONSE

		CLUSTERFQDN=${CLUSTERNAME}.${CLUSTERDOMAIN}
		CLUSTERWEBURL="https://console-openshift-console.apps.${CLUSTERFQDN}"
		CLUSTERAPIURL="https://api.${CLUSTERFQDN}:6443"
	
       		# GET BASENETWORK
       		echo
       		echo -n "Enter the SUBNET (/24) inside KVM that you want cluster under (\"${BASENETWORK}\"): "
       		read RESPONSE
       		[ ! -z "$RESPONSE" ] && BASENETWORK=$(echo $RESPONSE | cut -f1-3 -d.)


		### QUESTION: Get repository for VMs ## Stored in YAKKO defaults
		echo
		while [ 1 ]
		do
			echo -n "Enter an (existing) directory where you wish to place the OCP VM disks (\"${OCPVMDISKDIR}\"): "
			read RESPONSE
			[ -z "$RESPONSE" ] && RESPONSE=${OCPVMDISKDIR} && break
			[ -e "$RESPONSE" -a -d "$RESPONSE" ]  && break

			if [ ! -d "$RESPONSE" ]
			then
				echo "Invalid directory path. Please re-enter..."
				continue
                	fi
        	done
		OCPVMDISKDIR="$RESPONSE"

		### QUESTION: Add worker nodes at build ##
		WORKERNODECOUNT=0
		echo
		while [ 1 ]
                do
			echo "Worker nodes can be built at cluster creation or later."
			echo "To build a cluster with 3 schedulable MASTER nodes, type '0'"
			echo -n "How many worker nodes do you want to configure at cluster build time [0]: "
			read VALUE
			if [ ! -z "$VALUE" ]
			then
				NUMBERRE='^[0-9]+$'
				if ! [[ $VALUE =~ $NUMBERRE ]] ; then
					echo "Error: Not a number. Try again..."
					continue
				elif [ ${VALUE} -gt ${MAXWORKERNODES} ]
				then
					echo "You need to specify a number of workers up to ${MAXWORKERNODES} ]"
					continue
				else
					WORKERNODECOUNT=${VALUE}
					break
				fi
			else
				NUMBER=0
				echo "No worker nodes were requested. You can add nodes later with YAKKO."
				break
			fi
		done

		### QUESTION: RAM size confirmation (MASTERS/WORKERS)  ##
		echo
		while [ 1 ]
                do
                	echo -n "How much RAM (MiB) should be allocated to MASTER nodes [${MASTERRAMSIZE}]: "
			read VALUE
			if [ ! -z "$VALUE" ]
			then
				NUMBERRE='^[0-9]+$'
				if ! [[ $VALUE =~ $NUMBERRE ]] ; then
					echo "Error: Not a number. Try again..."
					continue
				else
					MASTERRAMSIZE=$VALUE
				fi
			fi
			break
		done
		echo

		if [ ${WORKERNODECOUNT} -gt 0 ]
		then 
		 	while [ 1 ]
                 	do
                 		echo -n "How much RAM (MiB) should be allocated to WORKER nodes [${WORKERRAMSIZE}]: "
		 		read VALUE
		 		if [ ! -z "$VALUE" ]
		 		then
		 			NUMBERRE='^[0-9]+$'
		 			if ! [[ $VALUE =~ $NUMBERRE ]] ; then
		 				echo "Error: Not a number. Try again..."
		 				continue
		 			else
		 				WORKERRAMSIZE=$VALUE
		 			fi
		 		fi
		 		break
		 	done
		 	echo
		fi

		# We write a bunch of stuff for later retrieval in $YAKKODEFAULTS
		CLUSTERPROXY="${BASENETWORK}.${PROXYADDRESS}"
                WEBSERVERIP=${CLUSTERPROXY}
                WEBSERVERPORT=8080

		populate-yakkodefaults
	
		### QUESTION: Cluster version

		# Now we get on with downloading the OCP binaries
		# NOTE: There can be discrepancies between the installer version (OCPGETCLIENTVERSION) and the RHCOS images version (OCPGETIMAGEVERSION)
		#	This script will download the lot under OCPGETCLIENTVERSION to keep a single point reference. This seems to make sense 
		#	based on what the OCP mirror offers.
		# 	HOWEVER, outside of the DOWNLOAD section of the script, the version will be known as OCPINSTALLVERSION
	
		# Get the OCP installer specifically for x86_64 
		OCPPLATFORM=x86_64
		OCPROOT=https://mirror.openshift.com/pub/openshift-v4/$OCPPLATFORM
	
		# This would get you the number for the latest version
		LATEST=latest # because sometimes latest isn't there yet...
		OCPDOWNLOADCLIENT="$OCPROOT/clients/ocp/latest"
		OCPDOWNLOADIMAGE="$OCPROOT/dependencies/rhcos/${LATEST}/latest"

		wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/release.txt > /dev/null 2>&1
		check-for-error-and-exit $? "Failed to download version file for latest OCP" 
			
	        OCPGETCLIENTVERSION=$(cat $OCPWGETTMP | grep Version: | awk '{ print $2 }')
		
		query-user "Use latest OCP version available ($OCPGETCLIENTVERSION)" "Y" noauto

	        if [ $? -ne 0 ]
	        then
			# Query what client is desired
			while [ 1 ]
			do
				echo -n  'Enter OCP INSTALLER CLIENT version you require, e.g. "4.5.6" (may not work btw...): ' 
				read OCPGETCLIENTVERSION
				OCPDOWNLOADCLIENT="$OCPROOT/clients/ocp/$OCPGETCLIENTVERSION"
		
				wget -O $OCPWGETTMP $OCPDOWNLOADCLIENT/sha256sum.txt >/dev/null 2>&1
				if [ $? -ne 0 ]
				then
					echo "Invalid version $OCPGETCLIENTVERSION, no content available"
				else
					break
				fi
			done

			# Query what RHCOS is desired
			while [ 1 ]
			do
				echo "Please refer to https://mirror.openshift.com/pub/openshift-v4/x86_64/dependencies/rhcos/${OCPGETCLIENTVERSION:0:3})"
				echo -n  'Enter OCP RHCOS version you require, e.g. "4.5.6" (may also not work btw...): ' 
				 # this is harder because of how the mirror is laid out
				read OCPGETIMAGEVERSION
				VERSIONMAJOR=$(echo $OCPGETIMAGEVERSION | cut -f1 -d.)
				VERSIONMINOR=$(echo $OCPGETIMAGEVERSION | cut -f2 -d.)
				VERSIONMICRO=$(echo $OCPGETIMAGEVERSION | cut -f3 -d.)
				OCPDOWNLOADIMAGE="$OCPROOT/dependencies/rhcos/$VERSIONMAJOR.$VERSIONMINOR/$OCPGETIMAGEVERSION"

				wget -O $OCPWGETTMP $OCPDOWNLOADIMAGE/sha256sum.txt >/dev/null 2>&1
				if [ $? -ne 0 ]
				then
					echo "Invalid version $OCPGETIMAGEVERSION, no content available"
				else
					break
				fi
			done
		fi
		echo
	
		populate-clusterconfigfile

		### QUESTION (last): Run auto setup
 
		# We reload the defaults...
		source ${YAKKODEFAULTS} > /dev/null 2>&1
		query-user "Attempt AUTOMATIC creation of cluster [${CLUSTERNAME}]" "Y" noauto  && AUTOSETUP=1
	}
	# NOTE: THIS STAGE MUST PRECEDE execute-yakko-stages
	# 	SEE MAIN AT BOTTOM

	[ $1 == "rollback" ] && {
		rollback-stage-progression "Cluster configuration gather"
		rm ${CLUSTERCONFIGFILE} > /dev/null 2>&1
		rm -rf $CLUSTERSETUPDIR > /dev/null 2>&1
	}
}




execute-yakko-stages() {

	ACTION=$1 # progress or rollback

	if [ "${ACTION}" == "rollback" ]
	then
		echo
		query-user "*** CONFIRM *** - Deleting cluster [${CLUSTERNAME}]" "N" noauto
		[ $? -ne 0 ] && { echo; echo "ATTENTION: No action taken. Exiting."; exit; }
		
		# User wants the cluster gone!
		AUTOSETUP=0
		process-stage-gatherclusterconfiguration rollback
	fi
	
	process-stage-pullsecret ${ACTION}
	process-stage-downloadocpbinaries ${ACTION}
	process-stage-libvirt ${ACTION}
	process-stage-sshclient ${ACTION}
	process-stage-virtualnetwork ${ACTION}
	process-stage-dns ${ACTION}
	process-stage-httpserver ${ACTION}
	process-stage-loadbalancer ${ACTION}
	process-stage-changefirewall ${ACTION}
	process-stage-generateocpinstallerconfig ${ACTION}
	process-stage-configurebootstrapnode ${ACTION}
	process-stage-configureocpmasternodes ${ACTION}
	process-stage-configureocpworkernodes ${ACTION}
	process-stage-startocpbootstrap ${ACTION}
	process-stage-approvecsrs ${ACTION}
	process-stage-reduceprometheusmemory ${ACTION}
	process-stage-waitforocpinstalltocomplete ${ACTION}
	

	if [ "${ACTION}" == "rollback" ]
	then
		echo
		echo "Cluster [${CLUSTERNAME}] (and all associated configuration) has been deleted."
		echo
		exit
	fi
}
						

######################################################################################################
##########  If this were a different programming language, you would call this a "main()".... ########
######################################################################################################

if [ "$1" == "backup" ]
then
	# This is action 0, the developer wants to make a backup
	# There will be no cluster built, nothing
	yakko-backup $*
fi

clear -x
print-in-green ${SEPARATIONLINE}
echo
print-in-green ' YAKKO: Yet Another KVM Konfigurator for Openshift'
print-in-green ${SEPARATIONLINE}
echo

if [ $(whoami) != 'root' ]
then 
	echo "ATTENTION: You must be user <root> to run ${YAKKONAME}"
	echo
	exit
fi

cd ${YAKKOSETUPDIR} >/dev/null 2>&1 # Just change to the directory of action from hereon
if [ $? -eq 1 ]
then 
	mkdir ${YAKKOSETUPDIR}
	cp $0 ${YAKKOSETUPDIR}

	echo Created directory ${YAKKOSETUPDIR}
	echo
	echo Execute ${YAKKOSETUPDIR}/${YAKKONAME} to configure OpenShift
	echo
	exit
fi

# We load YAKKO defaults whether they exist... or not.
source ${YAKKODEFAULTS} > /dev/null 2>&1

# HERE IT ALL BEGINS
# This is the last code group - a cluster config file exists or it doesn't

# if the user passed a parameter, let's capture it here... it could be "infra" or "ops"
YAKKOCALLOPTION=$1


if [ ! -r ${CLUSTERCONFIGFILE} ]
then
	[ ! -z "${YAKKOCALLOPTION}" ] && { echo "No cluster is configured. To begin, just run \"${YAKKONAME}\"." ; echo; exit; }
	process-stage-gatherclusterconfiguration progress
	execute-yakko-stages progress
else
	source ${CLUSTERCONFIGFILE} # Load config variables that this script accumulates

	# OK - the user wants to complete back out
	if [ "${YAKKOCALLOPTION}" == infra -a "$2" == deletecluster ]
	then
		yakko-infra-operations deletecluster $3
	fi

	if [ ! -z "${CLUSTERCOMPLETE}" ] 
	then

		# We first check to see if the cluster is powered up - and void hassle
		check-cluster-state 0 power
		if [ $? -eq 4 ]
		then

			# When the cluster is shutdown, you can start it or DELETE it!

			if [ "${YAKKOCALLOPTION}" == infra -a "$2" == startcluster ]
			then	
				yakko-infra-operations startcluster
			fi

			echo
			echo "The cluster is shutdown. Call 'yakko infra startcluster' to start it up!"
			echo
			exit
		fi	

		if [ $# -eq 0 ] # parameters go here when there is a cluster - see above and (backup: for developers)
		then
			check-cluster-state 1  # yakko is called on an existing cluster - check it!
			exit
		fi

		if [ $YAKKOCALLOPTION == "infra" ]
		then
			shift # we get rid of "infra"
			yakko-infra-operations $* # always exits
			check-cluster-state 1  # yakko is called on an existing cluster - check it! 1 makes it exit
		fi

		# This cluster is OPERATIONAL (not withstanding the state) 
		oc whoami | grep -e ":admin" -e "${YAKKOADMIN}"  > /dev/null
		AMIKUBEADMIN=$?
		if [ ${AMIKUBEADMIN} != 0 ]
		then
			echo "ATTENTION: You must be an OpenShift administrator to run ${YAKKONAME}"
			echo
			echo "If the kubeadmin user is still available you can login using:"
			echo "   oc login -u kubeadmin -p $(cat install-${CLUSTERNAME}/auth/kubeadmin-password) https://api.${CLUSTERFQDN}:6443"
			echo
			exit
		fi

		if [ $YAKKOCALLOPTION == "ops" ]
		then
			shift # we get rid of "ops"
			yakko-cluster-operations $* # always exits
			check-cluster-state 1  # yakko is called on an existing cluster - check it! 1 makes it exit
		fi

		echo "ERROR: Invalid argument passed [$YAKKOCALLOPTION]. "
		echo
		echo "USAGE: $YAKKONAME [ops <OPTION> [params] | infra <OPTION> [params]]"
		echo 
	else
		# This cluster is NOT OPERATIONAL - it's not technically a cluster at this point

		echo "There is no fully configured/operational OpenShift cluster"
		echo

		query-user "Continue configuring cluster [${CLUSTERNAME}]" "Y" noauto
		if [ $? -eq 0 ]
		then
			process-stage-continue-clusterconfiguration progress
			execute-yakko-stages progress
		else
			# Since there is no cluster, offer to delete
			query-user "Delete existing configuration progress for [${CLUSTERNAME}]" "Y" noauto
			if [ $? -eq 0 ]
			then
				execute-yakko-stages rollback
			fi
		fi
	fi
fi

####################################################################################
#####################                 YAKKO END!             #######################
####################################################################################
